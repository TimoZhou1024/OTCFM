\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2026} with \usepackage[nohyperref]{icml2026} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2026}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2026}

\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}

\icmltitlerunning{Optimal Transport Coupled Flow Matching for Alignment-Free and Robust Multi-View Clustering}

\begin{document}

\twocolumn[
  \icmltitle{Optimal Transport Coupled Flow Matching for \\
             Alignment-Free and Robust Multi-View Clustering}

  \icmlsetsymbol{equal}{*}

  \begin{icmlauthorlist}
    \icmlauthor{Anonymous Author}{equal}
  \end{icmlauthorlist}

  \icmlaffiliation{equal}{Anonymous Institution}

  \icmlcorrespondingauthor{Anonymous Author}{anon@example.com}

  \icmlkeywords{Multi-View Clustering, Flow Matching, Optimal Transport, Generative Models}

  \vskip 0.3in
]

\printAffiliationsAndNotice{}

\begin{abstract}
Multi-view clustering (MVC) confronts dual challenges in real-world deployments: data incompleteness (missing views) and structural misalignment (unaligned samples). While Diffusion Models (DMs) have shown promise in generative imputation, their stochastic nature and iterative sampling impose high computational latency, and they inherently lack mechanisms to handle unaligned cross-view structures. We propose \textbf{Optimal Transport Coupled Flow Matching (OT-CFM)}, a unified framework that leverages the deterministic nature of continuous normalizing flows and the geometric properties of Optimal Transport. Unlike traditional methods that require explicit alignment steps or stochastic multistep generation, OT-CFM learns a cross-view flow that optimally transports view-specific latent representations toward a structurally aligned consensus centroid. This process enables deterministic, efficient view completion and alignment-free fusion simultaneously. Specifically, we introduce: (1) a cross-view flow matching objective that learns transformations from each view to the consensus space; (2) a Gromov-Wasserstein structural coupling loss computed on encoded representations that aligns intra-view geometry \textit{without requiring sample correspondences}, making it suitable for unaligned scenarios; (3) a cosine similarity-based soft clustering mechanism; and (4) an optional contrastive regularization for aligned settings where sample correspondences are known. Experiments on benchmark datasets with varying degrees of missingness and misalignment demonstrate that OT-CFM achieves competitive performance with state-of-the-art methods while offering significantly faster inference.
\end{abstract}

\section{Introduction}\label{introduction}

Multi-view clustering (MVC) aims to partition samples into distinct groups by integrating information from diverse modalities. Despite its success, the field is hindered by two pervasive issues: Incomplete MVC (IMVC), where views are randomly missing, and Unaligned MVC (UMVC), where sample correspondences across views are unknown. Traditional approaches often treat these as separate problems, employing distinct pipelines for imputation and alignment, which leads to error propagation and suboptimal fusion.

Recently, Generative Diffusion Models (DMs) have emerged as a powerful tool for IMVC, utilizing conditional generation to recover missing views. However, DMs suffer from inherent limitations: (1) \textbf{Inference Latency}: The reliance on stochastic differential equations (SDEs) necessitates hundreds of sampling steps, prohibiting real-time applications; (2) \textbf{Alignment Dependency}: Standard conditional DMs require paired data for training, rendering them ineffective for UMVC scenarios where cross-view correspondence is absent.

Flow Matching (FM) represents a paradigm shift, offering a simulation-free approach to training Continuous Normalizing Flows (CNFs). By regressing a target vector field, FM enables deterministic and efficient probability path construction. Furthermore, the theoretical connection between FM and Optimal Transport (OT) suggests a potential for learning straight, structurally optimal trajectories between distributions.

Motivated by these insights, we propose a novel framework, \textbf{Optimal Transport Coupled Flow Matching (OT-CFM)}. We reformulate the MVC problem as learning a flow that transports view-specific latent representations to a unified consensus space. Our framework incorporates the following key innovations. First, we establish a \textit{Cross-View Flow Matching} mechanism that learns to transform each view's latent representation toward the consensus, rather than the standard noise-to-data flow. Second, we introduce a \textit{Gromov-Wasserstein Structural Regularization} computed on encoded representations, which encourages geometric consistency across views without explicit sample matching. Third, we employ an autoencoder architecture with \textit{Reconstruction and Contrastive Losses} that preserve view-specific information while enhancing cross-view consistency. Fourth, we adopt a \textit{Cosine Similarity-based Clustering} mechanism with temperature-scaled softmax assignments for improved clustering performance.

This paper makes the following contributions:
(1) We identify the limitations of stochastic diffusion in unaligned scenarios and propose a Flow Matching-based framework for simultaneous IMVC and UMVC.
(2) We develop a cross-view flow matching objective combined with Gromov-Wasserstein regularization that enforces structural alignment on encoded representations \textit{without requiring sample correspondences}, enabling true alignment-free multi-view learning.
(3) We introduce a modular loss function design where contrastive learning is applied only when sample correspondences are available, while GW-based structural alignment handles unaligned scenarios.
(4) We demonstrate that OT-CFM achieves competitive performance with significant speedups compared to diffusion baselines.

\section{Related Work}\label{related-work}

\textbf{Generative Models in MVC.} Deep generative models have evolved from Variational Autoencoders (VAEs) to Generative Adversarial Networks (GANs). Recently, Diffusion Models have dominated IMVC. Methods like IMVCDC utilize latent diffusion for missing view imputation, while DCG (Diffusion Contrastive Generation) employs diffusion steps to enhance clustering compactness. However, these methods are fundamentally limited by the computational cost of iterative denoising and the requirement for paired training data.

\textbf{Flow Matching and Optimal Transport.} Flow Matching simplifies the training of CNFs by directly regressing vector fields. Rectified Flow and Conditional Flow Matching (CFM) further optimize transport paths to be nearly straight, facilitating fast ODE solving. Concurrently, Optimal Transport (OT) has been applied to domain adaptation and alignment. Our work bridges these fields, utilizing OT to guide the flow matching process for multi-view structural alignment.

\textbf{Unaligned Multi-View Learning.} Traditional UMVC relies on combinatorial optimization to find permutation matrices or constructing large-scale similarity graphs, scaling poorly with dataset size ($O(N^2)$ or $O(N^3)$). Our method avoids explicit permutation solving by learning continuous transport maps, reducing complexity while handling misalignment.

\section{Preliminaries on Flow Matching for Multi-View Clustering}\label{preliminaries}

\subsection{Problem Formulation}\label{problem-formulation}

Consider a dataset with $V$ views $\mathcal{X} = \{ \mathbf{X}^{(v)} \}_{v=1}^V$, where $\mathbf{X}^{(v)} \in \mathbb{R}^{N \times d_v}$. In the general setting, both missing instances (IMVC) and unknown correspondences (UMVC) may exist. The goal is to learn a partition $\mathcal{C}$ of $K$ clusters.

\subsection{Flow Matching Basics}\label{flow-matching-basics}

Flow Matching aims to learn a time-dependent vector field $u_t: \mathbb{R}^d \to \mathbb{R}^d$ that generates a probability path $p_t$ transforming a source distribution $p_0$ (noise) to a target distribution $p_1$ (data). The flow is defined by the ODE:
\[
\frac{d\mathbf{z}_t}{dt} = u_t(\mathbf{z}_t), \quad \mathbf{z}_0 \sim p_0
\]
The Conditional Flow Matching (CFM) objective allows training without explicit access to $p_t$ and $u_t$ by conditioning on data samples $\mathbf{x}_1 \sim p_1$:
\[
\mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t, q(\mathbf{z}_1), p_t(\mathbf{z}|\mathbf{z}_1)} \| v_\theta(\mathbf{z}, t) - u_t(\mathbf{z}|\mathbf{z}_1) \|^2
\]
where $u_t(\mathbf{z}|\mathbf{z}_1)$ is the conditional vector field, typically chosen to induce a straight path $\mathbf{z}_t = t\mathbf{x}_1 + (1-t)\mathbf{x}_0$.

\section{Optimal Transport Coupled Flow Matching (OT-CFM)}\label{method}

We propose OT-CFM to address the structural misalignment and computational inefficiency of current methods. The framework consists of latent embedding, OT-guided vector field learning, and deterministic ODE fusion.

\subsection{Latent Space Construction}\label{latent-space}

We address the challenge of high-dimensional and heterogeneous multi-view data by projecting raw features into a unified low-dimensional latent space. Let $\mathcal{X} = \{ \mathbf{X}^{(v)} \in \mathbb{R}^{N \times d_v} \}_{v=1}^V$ denote the multi-view dataset with $N$ samples and $V$ views. For each view $v$, we employ a specific neural encoder $f_{\phi_v}: \mathbb{R}^{d_v} \to \mathbb{R}^{d_z}$ parameterized by $\phi_v$ to map the observation $\mathbf{x}_i^{(v)}$ to a latent representation $\mathbf{z}_i^{(v)} = f_{\phi_v}(\mathbf{x}_i^{(v)})$. 

\textbf{Encoder Architecture.} Each view-specific encoder is implemented as a multi-layer perceptron (MLP) with batch normalization, ReLU activation, and dropout regularization. To facilitate gradient flow and preserve low-level features, we incorporate a scaled skip connection from input to output:
\[
\mathbf{z}^{(v)} = \text{MLP}_{\phi_v}(\mathbf{x}^{(v)}) + \alpha \cdot W_{skip} \mathbf{x}^{(v)}
\]
where $\alpha = 0.1$ is a scaling factor and $W_{skip}$ is a linear projection when $d_v \neq d_z$.

\textbf{Decoder Architecture.} Symmetric to the encoders, we employ view-specific decoders $g_{\psi_v}: \mathbb{R}^{d_z} \to \mathbb{R}^{d_v}$ that reconstruct the original views from latent representations. This autoencoder structure provides a reconstruction objective that regularizes the latent space.

\textbf{Consensus Fusion (Aligned Setting).} For aligned multi-view data where sample correspondences are known, the multi-view consensus representation is obtained by averaging the view-specific latents:
\[
\mathbf{z}^{(c)} = \frac{1}{|\mathcal{V}_{avail}|} \sum_{v \in \mathcal{V}_{avail}} \mathbf{z}^{(v)}
\]
where $\mathcal{V}_{avail}$ denotes the set of available views. This averaging is semantically meaningful because $\mathbf{z}_i^{(v)}$ and $\mathbf{z}_i^{(u)}$ correspond to the same underlying sample $i$.

\textbf{Centroid-based Conditioning (Unaligned Setting).} For unaligned multi-view data (UMVC), the $i$-th sample in view $v$ does \textit{not} correspond to the $i$-th sample in view $u$. Therefore, \textbf{averaging latents across views is mathematically invalid}. Instead, we adopt a per-view cluster-centroid-based approach:
\begin{enumerate}
    \item For each view $v$, compute soft cluster assignments $q_{ik}^{(v)}$ based solely on $\mathbf{z}_i^{(v)}$ and the shared centroids $\{\boldsymbol{\mu}_k\}_{k=1}^K$.
    \item Use the nearest cluster centroid $\boldsymbol{\mu}_{k^{*(v)}}$ as the view-specific conditioning, where $k^{*(v)} = \argmax_k q_{ik}^{(v)}$.
\end{enumerate}
Critically, \textbf{no cross-view averaging is performed} at any stage. Each view's sample is independently assigned to a cluster based on its own latent representation. This design ensures that imputation and generation are conditioned on semantically coherent representations (cluster prototypes) rather than meaningless cross-sample averages.

This encoding process serves two primary purposes: it reduces the computational complexity of the subsequent flow matching operations by operating in a lower-dimensional manifold $d_z \ll d_v$, and it filters out modality-specific noise while preserving the intrinsic semantic structure. The resulting latent representations $\mathcal{Z} = \{ \mathbf{Z}^{(v)} \in \mathbb{R}^{N \times d_z} \}_{v=1}^V$ form the basis for our flow-based alignment and generation mechanism.

\subsection{Gromov-Wasserstein Guided Vector Field}\label{gw-vector-field}

In the context of Unaligned Multi-View Clustering (UMVC), the correspondence between samples across different views is unknown, rendering standard point-wise distance minimization invalid. To overcome this, we leverage the Gromov-Wasserstein (GW) distance to align the geometric structures of the view-specific distributions. We define the intra-view relational geometry using kernel matrices computed on the encoded latent representations.

\textbf{Kernel Matrix Construction.} Let $\mathbf{K}^{(v)} \in \mathbb{R}^{B \times B}$ represent the pairwise similarity matrix for view $v$ within a mini-batch of size $B$. We employ the RBF (Radial Basis Function) kernel:
\[
K_{ij}^{(v)} = \exp\left(-\gamma \| \mathbf{z}_i^{(v)} - \mathbf{z}_j^{(v)} \|^2\right)
\]
where $\gamma$ is the kernel bandwidth parameter. To ensure numerical stability, we normalize the kernel matrix to the range $[0, 1]$.

\textbf{Structural Alignment Loss.} The GW loss measures the Frobenius norm of the difference between kernel matrices across view pairs:
\[
\mathcal{L}_{GW} = \frac{2}{V(V-1)} \sum_{v < u} \| \mathbf{K}^{(v)} - \mathbf{K}^{(u)} \|_F^2
\]
This formulation encourages the pairwise geometric relationships to be consistent across views without requiring explicit sample correspondences. By minimizing this loss, samples with similar topological roles in their respective views are encouraged to have similar relative positions in the latent space.

Note that in our implementation, the GW loss is computed on the encoded latent representations $\mathbf{z}^{(v)}$ directly, rather than on the intermediate states $\mathbf{z}_t$ during the flow process. This design choice simplifies the computation while still providing effective structural alignment through the gradient signal that propagates back to the encoder parameters.

\textbf{Computational Complexity.} While GW distance computation scales quadratically with sample size, we compute it within mini-batches of size $B$, yielding $O(B^2)$ per batch. Since our goal is to align the \textit{manifold geometry} rather than global point-wise matching, batch-wise structural alignment provides a sufficient gradient signal for the encoders while maintaining linear complexity $O(N)$ with respect to the total dataset size.

\subsection{Conditional Straight-Flow for Imputation}\label{conditional-flow}

To address the Incomplete Multi-View Clustering (IMVC) problem, we formulate the missing view imputation as a conditional generation task within the flow matching framework. Let $\mathcal{V}_{avail}$ denote the set of indices for observed views and $\mathcal{V}_{miss}$ for missing views. We aim to learn a time-dependent vector field $v_\theta(\mathbf{z}_t, t, \mathbf{c})$ that generates the missing latent representations conditioned on a conditioning vector $\mathbf{c}$.

\textbf{Conditioning Strategy.} The choice of conditioning $\mathbf{c}$ depends on the data alignment:
\begin{itemize}
    \item \textbf{Aligned (IMVC):} $\mathbf{c} = \mathbf{z}^{(c)}$, the consensus computed from available views.
    \item \textbf{Unaligned (UMVC):} $\mathbf{c} = \boldsymbol{\mu}_{k^*}$, the nearest cluster centroid based on available view latents.
\end{itemize}

\textbf{Imputation Procedure.} During inference, for samples with missing views, we:
\begin{enumerate}
    \item Encode all available views to obtain $\{\mathbf{z}^{(v)}\}_{v \in \mathcal{V}_{avail}}$.
    \item Compute the conditioning vector $\mathbf{c}$ (consensus or cluster centroid).
    \item Sample initial noise $\mathbf{z}_0 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ for each missing view.
    \item Solve the ODE $\frac{d\mathbf{z}_t}{dt} = v_\theta(\mathbf{z}_t, t, \mathbf{c})$ using the Euler method with $N_{steps} = 10$ integration steps.
    \item Decode the generated latent to obtain the imputed view.
\end{enumerate}

We adopt the Optimal Transport Conditional Flow Matching (OT-CFM) formulation, which constructs a probability path that optimally transports a standard Gaussian noise distribution $p_0(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I})$ to the data distribution $p_1(\mathbf{z})$. The target conditional vector field $u_t(\mathbf{z} | \mathbf{z}_0, \mathbf{z}_1)$ is defined to generate straight trajectories:
\[
u_t(\mathbf{z} | \mathbf{z}_0, \mathbf{z}_1) = \mathbf{z}_1 - (1 - \sigma_{min})\mathbf{z}_0
\]
corresponding to the interpolation path $\mathbf{z}_t = (1 - (1 - \sigma_{min})t)\mathbf{z}_0 + t\mathbf{z}_1$, where $\sigma_{min} = 10^{-4}$ is a small constant for numerical stability.

\textbf{Vector Field Architecture.} The neural vector field $v_\theta$ employs a residual architecture with time conditioning. Time is embedded using sinusoidal positional encoding followed by an MLP, similar to diffusion models. The network consists of residual blocks where each block incorporates the time embedding through an additive modulation:
\[
\mathbf{h}_{l+1} = \mathbf{h}_l + \text{MLP}(\text{LayerNorm}(\mathbf{h}_l) + \text{TimeEmbed}(t))
\]

The linearity of the OT-CFM path allows us to employ fixed-step ODE solvers with a very small number of function evaluations (NFE $\leq 10$), resulting in a deterministic and computationally efficient imputation process.

\subsection{Overall Objective Function}\label{overall-objective}

The training of the OT-CFM framework is governed by a unified objective function that integrates flow matching accuracy, structural alignment, clustering compactness, reconstruction fidelity, and cross-view consistency. 

\textbf{Generative Flow Matching Loss.} We adopt the standard Conditional Flow Matching (CFM) objective that learns to transport noise to data, conditioned on a semantic anchor. Let $\mathbf{z}_0 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ be the noise sample, $\mathbf{z}_1$ be the target latent (data), and $\mathbf{c}$ be the conditioning vector (consensus for aligned, cluster centroid for unaligned). The CFM loss is:
\[
\mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t \sim [0,1], \mathbf{z}_0, \mathbf{z}_1} \left[ \| v_\theta(\mathbf{z}_t, t, \mathbf{c}) - (\mathbf{z}_1 - (1-\sigma_{min})\mathbf{z}_0) \|^2 \right]
\]
where $\mathbf{z}_t = (1 - (1 - \sigma_{min})t)\mathbf{z}_0 + t\mathbf{z}_1$ is the interpolation path. This formulation trains a \textit{generative} flow (Noise $\to$ Data) that can synthesize missing view latents at inference time.

\textbf{Remark.} An alternative \textit{cross-view} formulation learns to flow from view latents to consensus: $\psi_t(\mathbf{z}^{(v)}, \mathbf{z}^{(c)})$. While this provides an auxiliary training signal for representation learning, the \textit{generative} formulation above is essential for imputation, as it enables sampling from noise.

\textbf{Gromov-Wasserstein Structural Alignment.} To enforce geometric consistency across unaligned views, we incorporate the Gromov-Wasserstein regularization $\mathcal{L}_{GW}$ computed on the encoded latent representations using RBF kernel matrices.

\textbf{Clustering Loss.} We employ a cosine similarity-based soft assignment mechanism. Let $\tilde{\mathbf{z}}_i = \mathbf{z}_i / \|\mathbf{z}_i\|$ and $\tilde{\boldsymbol{\mu}}_k = \boldsymbol{\mu}_k / \|\boldsymbol{\mu}_k\|$ denote the normalized embeddings and centroids. The soft assignment probability is computed via temperature-scaled softmax:
\[
q_{ik} = \frac{\exp(\tilde{\mathbf{z}}_i^\top \tilde{\boldsymbol{\mu}}_k / \tau)}{\sum_{j=1}^{K} \exp(\tilde{\mathbf{z}}_i^\top \tilde{\boldsymbol{\mu}}_j / \tau)}
\]
where $\tau$ is the temperature parameter. The auxiliary target distribution $P$ sharpens high-confidence assignments: $p_{ik} \propto q_{ik}^2 / \sum_i q_{ik}$. The clustering loss is the KL divergence:
\[
\mathcal{L}_{Cluster} = KL(P \| Q) = \sum_{i} \sum_{k} p_{ik} \log \frac{p_{ik}}{q_{ik}}
\]

\textbf{Reconstruction Loss.} To preserve view-specific information and regularize the latent space, we include a reconstruction loss through view-specific decoders:
\[
\mathcal{L}_{Recon} = \frac{1}{V} \sum_{v=1}^{V} \| \mathbf{X}^{(v)} - g_{\psi_v}(\mathbf{z}^{(v)}) \|_F^2
\]
where $g_{\psi_v}$ is the decoder for view $v$.

\textbf{Contrastive Loss (Aligned Setting Only).} For scenarios where sample correspondences are known (standard IMVC), we can additionally employ an InfoNCE-based contrastive loss to enhance cross-view consistency:
\[
\mathcal{L}_{Contrastive} = -\frac{1}{V(V-1)} \sum_{v \neq u} \sum_{i} \log \frac{\exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\mathbf{z}}_i^{(u)} / \tau_c)}{\sum_{j} \exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\mathbf{z}}_j^{(u)} / \tau_c)}
\]
where $\tau_c$ is the contrastive temperature. \textbf{Importantly, this loss is only applicable when sample correspondences across views are available.} In the unaligned setting (UMVC), where the $i$-th sample in view $v$ does not correspond to the $i$-th sample in view $u$, this loss must be disabled ($\lambda_{con} = 0$). The GW loss $\mathcal{L}_{GW}$ serves as the sole mechanism for cross-view structural alignment in UMVC, as it operates on pairwise geometric relationships rather than point-wise correspondences.

\textbf{Total Objective.} The complete objective is a weighted combination:
\[
\mathcal{L}_{Total} = \mathcal{L}_{CFM} + \lambda_{gw} \mathcal{L}_{GW} + \lambda_{c} \mathcal{L}_{Cluster} + \lambda_{r} \mathcal{L}_{Recon} + \lambda_{con} \mathcal{L}_{Contrastive}
\]
where we set $\lambda_{gw} = 0.2$, $\lambda_{c} = 1.0$, $\lambda_{r} = 0.5$ as default hyperparameters. The contrastive weight $\lambda_{con}$ is set to $0.3$ for aligned data and $0$ for unaligned data. Table~\ref{tab:loss_config} summarizes the loss configurations for different scenarios.

\begin{table}[h]
\centering
\caption{Loss function configuration for different MVC scenarios.}
\label{tab:loss_config}
\begin{tabular}{lcc}
\toprule
\textbf{Component} & \textbf{Aligned (IMVC)} & \textbf{Unaligned (UMVC)} \\
\midrule
\textbf{Flow Conditioning} & Consensus $\mathbf{z}^{(c)}$ & Centroid $\boldsymbol{\mu}_{k^*}$ \\
$\mathcal{L}_{CFM}$ (Generative) & \checkmark & \checkmark \\
$\mathcal{L}_{GW}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Cluster}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Recon}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Contrastive}$ & \checkmark & $\times$ \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\footnotesize{The generative CFM loss is always active; only the conditioning source differs.}
\end{table}

\subsection{Optimization Procedure}\label{optimization}

Directly optimizing the joint objective $\mathcal{L}_{Total}$ is challenging due to the coupling between the flow matching dynamics, the structural alignment, and the discrete nature of clustering assignments. We adopt an end-to-end training approach with periodic clustering refinement, which offers better gradient flow while maintaining clustering quality.

\textbf{Network Architecture.} Our encoder-decoder architecture employs view-specific MLP encoders with skip connections to map high-dimensional inputs to a shared latent space. Each encoder consists of fully-connected layers with batch normalization, ReLU activation, and dropout regularization. A scaled skip connection ($0.1\times$) from input to output helps preserve low-level features. The vector field network uses residual blocks with time conditioning via sinusoidal embeddings, following the design principles of diffusion models.

\textbf{Training Procedure.} The optimization follows a two-phase approach to address the cold-start problem, where good centroids require a stable latent space, but a good latent space benefits from meaningful conditioning:
\begin{enumerate}
    \item \textbf{Warm-up Phase:} We first train the encoder-decoder using only $\mathcal{L}_{Recon}$ for a few epochs to establish a stable latent space. Then, we collect all latent embeddings and initialize cluster centroids using K-Means on the normalized embeddings. This warm-up is crucial for unaligned scenarios where initial centroid quality directly affects flow training.
    \item \textbf{Joint Training Phase:} We perform end-to-end optimization of all network parameters using the combined loss $\mathcal{L}_{Total}$. The cluster centroids are treated as learnable parameters updated via gradient descent. Periodically (every few epochs), we refine the centroids using K-Means on the current embeddings to prevent degenerate solutions.
\end{enumerate}

\textbf{Implementation Details.} We use the Adam optimizer with learning rate $10^{-3}$ and apply gradient clipping with max norm 1.0 to stabilize training. The ODE solver employs the Euler method with 10 integration steps for efficiency. During inference, cluster assignments are obtained by taking the argmax of the soft assignment probabilities.

The complete training process is summarized in Algorithm \ref{alg:ot_cfm}.

\begin{algorithm}[tb]
  \caption{End-to-End Training for OT-CFM}
  \label{alg:ot_cfm}
  \begin{algorithmic}
    \STATE {\bfseries Input:} Multi-view data $\mathcal{X}$, Number of clusters $K$, Hyperparameters $\lambda_{gw}, \lambda_{c}, \lambda_{r}, \lambda_{con}$, Alignment flag \texttt{is\_aligned}.
    \STATE {\bfseries Initialize:} Encoder-decoder parameters $\phi$, Vector field parameters $\theta$, Cluster centroids $\mathbf{M}$ via K-Means on initial embeddings.
    \FOR{epoch $= 1$ to $E$}
    \FOR{each mini-batch $\mathcal{B} \subset \mathcal{X}$}
        \STATE Encode views: $\mathbf{z}^{(v)} = f_{\phi_v}(\mathbf{x}^{(v)})$ for all views.
        \IF{\texttt{is\_aligned}}
            \STATE Compute consensus: $\mathbf{z}^{(c)} = \frac{1}{V}\sum_v \mathbf{z}^{(v)}$.
            \STATE Condition $\mathbf{c} \gets \mathbf{z}^{(c)}$.
        \ELSE
            \STATE \textit{// Unaligned: do NOT average across views.}
            \STATE For each view $v$, compute per-view assignments:
            \STATE \quad $q_{ik}^{(v)} = \frac{\exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\boldsymbol{\mu}}_k / \tau)}{\sum_j \exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\boldsymbol{\mu}}_j / \tau)}$
            \STATE \quad $k^{*(v)} = \argmax_k q_{ik}^{(v)}$
            \STATE Condition $\mathbf{c}^{(v)} \gets \boldsymbol{\mu}_{k^{*(v)}}$ (view-specific centroid).
        \ENDIF
        \STATE Sample noise $\mathbf{z}_0 \sim \mathcal{N}(0, I)$ and time $t \sim \mathcal{U}[0,1]$.
        \STATE Compute CFM Loss: $\mathcal{L}_{CFM} = \| v_\theta(\mathbf{z}_t, t, \mathbf{c}) - (\mathbf{z}_1 - (1-\sigma_{min})\mathbf{z}_0) \|^2$.
        \STATE Compute GW Alignment Loss $\mathcal{L}_{GW}$ on encoded latents.
        \STATE Compute Clustering Loss $\mathcal{L}_{Cluster} = KL(P_{\mathcal{B}} \| Q_{\mathcal{B}})$.
        \STATE Compute $\mathcal{L}_{Recon}$; compute $\mathcal{L}_{Contrastive}$ only if \texttt{is\_aligned}.
        \STATE Update all parameters via Adam with gradient clipping.
    \ENDFOR
    \IF{epoch mod $T_{update} = 0$}
        \STATE Refine centroids $\mathbf{M}$ via K-Means on current embeddings.
    \ENDIF
    \ENDFOR
    \STATE {\bfseries Output:} Trained model, Cluster assignments $\argmax_k q_{ik}$.
  \end{algorithmic}
\end{algorithm}


\bibliography{ref}
\bibliographystyle{icml2026}

\end{document}