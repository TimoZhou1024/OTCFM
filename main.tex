\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables
\usepackage{multirow} % for multi-row tables
\usepackage{tabularx} 
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2026} with \usepackage[nohyperref]{icml2026} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2026}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2026}

\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}

\icmltitlerunning{Optimal Transport Coupled Flow Matching for Alignment-Free and Robust Multi-View Clustering}

\begin{document}

\twocolumn[
  \icmltitle{Optimal Transport Coupled Flow Matching for \\
             Alignment-Free and Robust Multi-View Clustering}

  \icmlsetsymbol{equal}{*}

  \begin{icmlauthorlist}
    \icmlauthor{Anonymous Author}{equal}
  \end{icmlauthorlist}

  \icmlaffiliation{equal}{Anonymous Institution}

  \icmlcorrespondingauthor{Anonymous Author}{anon@example.com}

  \icmlkeywords{Multi-View Clustering, Flow Matching, Optimal Transport, Generative Models}

  \vskip 0.3in
]

\printAffiliationsAndNotice{}

\begin{abstract}
Multi-view clustering (MVC) confronts dual challenges in real-world deployments: data incompleteness (missing views) and structural misalignment (unaligned samples). While Diffusion Models (DMs) have shown promise in generative imputation, their stochastic nature and iterative sampling impose high computational latency, and they inherently lack mechanisms to handle unaligned cross-view structures. We propose \textbf{Optimal Transport Coupled Flow Matching (OT-CFM)}, a unified framework that leverages the deterministic nature of continuous normalizing flows and the geometric properties of Optimal Transport. Unlike traditional methods that require explicit alignment steps or stochastic multistep generation, OT-CFM learns a cross-view flow that optimally transports view-specific latent representations toward a structurally aligned consensus centroid. This process enables deterministic, efficient view completion and alignment-free fusion simultaneously. Specifically, we introduce: (1) a cross-view flow matching objective that learns transformations from each view to the consensus space; (2) a Gromov-Wasserstein structural coupling loss computed on encoded representations that aligns intra-view geometry \textit{without requiring sample correspondences}, making it suitable for unaligned scenarios; (3) a cosine similarity-based soft clustering mechanism; and (4) an optional contrastive regularization for aligned settings where sample correspondences are known. Experiments on benchmark datasets with varying degrees of missingness and misalignment demonstrate that OT-CFM achieves competitive performance with state-of-the-art methods while offering significantly faster inference.
\end{abstract}

\section{Introduction}\label{introduction}

Multi-view clustering (MVC) aims to partition samples into distinct groups by integrating complementary information from multiple heterogeneous data sources, and has attracted significant attention in machine learning and data mining communities \cite{yang2022survey,chao2021survey}. However, most existing MVC methods \cite{kumar2011co,nie2016parameter,zhang2019ae2nets} are designed for \textit{ideal} multi-view data, which assumes that all views are \textit{complete} (every sample has observations in all views) and \textit{aligned} (samples across different views have known one-to-one correspondences). In real-world applications, such ideal assumptions are often violated. For instance, in medical diagnosis, a patient may have CT scans but lack MRI images due to cost or availability constraints, resulting in \textit{incomplete} views \cite{lin2021completer}. 
In social media analysis, user profiles across different platforms (e.g., Twitter and LinkedIn) often lack explicit linking, creating naturally unaligned multi-view scenarios \cite{gong2025multi}. Consequently, the problem of clustering multi-view data under simultaneous incompleteness and misalignment remains largely unresolved, posing a fundamental challenge to existing multi-view learning paradigms. %%In cross-lingual document clustering, different language versions of documents may not have explicit correspondence annotations, leading to \textit{unaligned} views \cite{huang2020partially}. Similarly,  How to effectively cluster such non-ideal multi-view data---characterized by incompleteness and misalignment---has emerged as a critical research challenge.

To address these challenges, recent works have focused on either incomplete multi-view clustering (IMVC) or unaligned multi-view clustering (UMVC). For the \textit{incomplete} multi-view scenario (IMVC), COMPLETER \cite{lin2021completer} employs contrastive learning to predict missing views through cross-view feature alignment, while SURE \cite{liu2022sure} integrates uncertainty estimation into the view recovery process for robust imputation. DealMVC \cite{jin2023dealmvc} further introduces dual contrastive prediction with prototype alignment to handle partial sample and view missing. More recently, diffusion-based methods such as DCG \cite{wang2025dcg} leverage conditional diffusion models to generate missing views and enhance clustering compactness through iterative denoising. For the \textit{unaligned} multi-view scenario (UMVC), PVC \cite{huang2020partially} formulates alignment as a permutation learning problem using differentiable matching networks. MRG-UMC \cite{gong2025multi} constructs multi-level reliable guidance for unpaired samples by exploiting both local and global structural information, and CANDY \cite{yang2024candy} addresses dual noisy correspondence via robust contrastive learning with noise-tolerant mechanisms.

Although these methods have achieved promising performance in incomplete or unaligned multi-view clustering, they still suffer from several critical limitations. \textbf{First}, existing imputation-based and diffusion-based methods rely on stochastic differential equations (SDEs) that necessitate hundreds of iterative sampling steps \cite{ho2020ddpm,song2021scorebased}, resulting in prohibitive computational latency that hinders real-time applications. \textbf{Second}, most methods treat incomplete and unaligned scenarios as separate problems, employing distinct pipelines for view imputation and correspondence alignment respectively. This two-stage paradigm leads to error propagation between stages and suboptimal multi-view fusion. \textbf{Third}, existing alignment methods typically require explicit correspondence supervision or rely on expensive combinatorial optimization (e.g., the Hungarian algorithm with $O(N^3)$ complexity), which severely limits their scalability to large-scale datasets.

To address the aforementioned limitations, we propose \textbf{Optimal Transport Coupled Flow Matching (OT-CFM)}, a unified framework that simultaneously handles incomplete and unaligned multi-view clustering in a principled manner. Our key insight is that Flow Matching (FM) \cite{lipman2023flowmatching,liu2023rectifiedflow} provides a simulation-free approach to training Continuous Normalizing Flows (CNFs), enabling deterministic and efficient probability path construction. By regressing a target vector field rather than iteratively denoising, FM achieves comparable generation quality with orders of magnitude fewer function evaluations \cite{tong2024otcfm}. Furthermore, the theoretical connection between FM and Optimal Transport (OT) provides a principled way to learn geometrically optimal trajectories between view-specific distributions. Specifically, OT-CFM reformulates multi-view clustering as learning a flow that transports view-specific latent representations to a unified consensus space. Our framework introduces: \textbf{(1)} A \textit{Cross-View Flow Matching} mechanism that learns transformations from each view's latent space toward a shared consensus, enabling efficient missing view imputation through deterministic ODE solving with only 10 function evaluations. \textbf{(2)} A \textit{Gromov-Wasserstein Structural Regularization} computed on encoded representations that aligns intra-view geometric structures \textit{without requiring sample correspondences}, making it naturally suitable for unaligned scenarios. \textbf{(3)} A modular loss design where \textit{Contrastive Regularization} is applied only when correspondences are known (aligned setting), while GW-based alignment operates in all scenarios. \textbf{(4)} A \textit{Cosine Similarity-based Clustering} mechanism with temperature-scaled softmax assignments for improved clustering performance.

In summary, our contributions are as follows:
\begin{itemize}
    \item We propose OT-CFM, a unified framework that addresses both incomplete and unaligned multi-view clustering through flow matching, achieving deterministic inference with significantly lower latency than diffusion-based methods.
    \item We develop a Gromov-Wasserstein structural coupling loss that enforces cross-view geometric consistency \textit{without requiring sample correspondences}, enabling true alignment-free multi-view learning.
    \item We introduce a modular architecture that adaptively activates contrastive learning for aligned data while relying on GW-based structural alignment for unaligned scenarios.
    \item Extensive experiments on benchmark datasets demonstrate that OT-CFM achieves competitive or superior performance compared to state-of-the-art methods while offering 10-100$\times$ faster inference.
\end{itemize}

\section{Related Work}\label{related-work}

\textbf{Incomplete MVC and Generative Models.} 
Handling missing views is a pivotal challenge in MVC. Early approaches relied on matrix factorization or graph learning to impute missing information implicitly \cite{liu2022sure}. With the advent of deep learning, generative models have become mainstream. Methods like COMPLETER \cite{lin2021completer} and DeepIMVC \cite{jin2023dealmvc} utilize contrastive learning and prototype alignment to recover missing representations. More recently, Diffusion Models (DMs) \cite{ho2020ddpm, song2021scorebased} have been introduced to MVC for their superior generation quality. For instance, DCG \cite{wang2025dcg} employs conditional diffusion to generate missing views and enhance clustering compactness. Despite their success, diffusion-based methods suffer from high inference latency due to the iterative denoising process (requiring hundreds of steps) and typically rely on paired data for training, limiting their efficiency and applicability in real-time scenarios.

\textbf{Unaligned Multi-View Learning.} 
Most MVC algorithms assume a strict one-to-one correspondence across views. When this assumption is violated (i.e., unaligned MVC), performance degrades significantly. Existing solutions usually formulate alignment as a permutation learning problem. PVC \cite{huang2020partially} and its successors employ differentiable matching networks to infer correspondences. Recent works like MRG-UMC \cite{gong2025multi} and CANDY \cite{yang2024candy} introduce multi-level guidance and robust contrastive learning to handle noisy or unpaired data. However, these methods often involve solving the assignment problem (e.g., via the Hungarian algorithm), which scales poorly ($O(N^3)$) with dataset size. Furthermore, they typically treat alignment and clustering as separate stages or alternating objectives, lacking a unified framework to handle structural misalignment implicitly.

\textbf{Flow Matching and Optimal Transport.} 
Flow Matching (FM) \cite{lipman2023flowmatching} has emerged as a simulation-free alternative to diffusion models, learning a deterministic Continuous Normalizing Flow (CNF) by regressing a target vector field. Rectified Flow \cite{liu2023rectifiedflow} and OT-CFM \cite{tong2024otcfm} further optimize the transport path to be straight, enabling fast sampling with few-step ODE solvers. The connection between FM and Optimal Transport (OT) provides a geometric perspective on distribution alignment. While OT has been applied to domain adaptation, its integration with Flow Matching for unsupervised multi-view clustering—specifically to address incompleteness and misalignment simultaneously—remains unexplored. Our work bridges this gap by leveraging OT-guided flows for efficient imputation and alignment-free fusion.

\section{Preliminaries on Flow Matching for Multi-View Clustering}\label{preliminaries}

\subsection{Problem Formulation}\label{problem-formulation}

Consider a dataset with $V$ views $\mathcal{X} = \{ \mathbf{X}^{(v)} \}_{v=1}^V$, where $\mathbf{X}^{(v)} \in \mathbb{R}^{N \times d_v}$. In the general setting, both missing instances (IMVC) and unknown correspondences (UMVC) may exist. The goal is to learn a partition $\mathcal{C}$ of $K$ clusters.

\subsection{Flow Matching Basics}\label{flow-matching-basics}

Flow Matching aims to learn a time-dependent vector field $u_t: \mathbb{R}^d \to \mathbb{R}^d$ that generates a probability path $p_t$ transforming a source distribution $p_0$ (noise) to a target distribution $p_1$ (data). The flow is defined by the ODE:
\[
\frac{d\mathbf{z}_t}{dt} = u_t(\mathbf{z}_t), \quad \mathbf{z}_0 \sim p_0
\]
The Conditional Flow Matching (CFM) objective allows training without explicit access to $p_t$ and $u_t$ by conditioning on data samples $\mathbf{x}_1 \sim p_1$:
\[
\mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t, q(\mathbf{z}_1), p_t(\mathbf{z}|\mathbf{z}_1)} \| v_\theta(\mathbf{z}, t) - u_t(\mathbf{z}|\mathbf{z}_1) \|^2
\]
where $u_t(\mathbf{z}|\mathbf{z}_1)$ is the conditional vector field, typically chosen to induce a straight path $\mathbf{z}_t = t\mathbf{x}_1 + (1-t)\mathbf{x}_0$.

\section{Optimal Transport Coupled Flow Matching (OT-CFM)}\label{method}

We propose OT-CFM to address the structural misalignment and computational inefficiency of current methods. The framework consists of latent embedding, OT-guided vector field learning, and deterministic ODE fusion. Figure~\ref{fig:overview} illustrates the overall architecture of our proposed method.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{overview.jpg}
    \caption{Overview of the proposed OT-CFM framework. The architecture consists of view-specific encoders that project heterogeneous inputs into a unified latent space, a conditional flow matching module that learns optimal transport paths from noise to data conditioned on semantic anchors, and a Gromov-Wasserstein structural alignment mechanism that enforces cross-view geometric consistency without requiring sample correspondences.}
    \label{fig:overview}
\end{figure*}

\subsection{Latent Space Construction}\label{latent-space}

We address the challenge of high-dimensional and heterogeneous multi-view data by projecting raw features into a unified low-dimensional latent space. Let $\mathcal{X} = \{ \mathbf{X}^{(v)} \in \mathbb{R}^{N \times d_v} \}_{v=1}^V$ denote the multi-view dataset with $N$ samples and $V$ views. For each view $v$, we employ a specific neural encoder $f_{\phi_v}: \mathbb{R}^{d_v} \to \mathbb{R}^{d_z}$ parameterized by $\phi_v$ to map the observation $\mathbf{x}_i^{(v)}$ to a latent representation $\mathbf{z}_i^{(v)} = f_{\phi_v}(\mathbf{x}_i^{(v)})$. 

\textbf{Encoder Architecture.} Each view-specific encoder is implemented as a multi-layer perceptron (MLP) with batch normalization, ReLU activation, and dropout regularization. To facilitate gradient flow and preserve low-level features, we incorporate a scaled skip connection from input to output:
\[
\mathbf{z}^{(v)} = \text{MLP}_{\phi_v}(\mathbf{x}^{(v)}) + \alpha \cdot W_{skip} \mathbf{x}^{(v)}
\]
where $\alpha = 0.1$ is a scaling factor and $W_{skip}$ is a linear projection when $d_v \neq d_z$.

\textbf{Decoder Architecture.} Symmetric to the encoders, we employ view-specific decoders $g_{\psi_v}: \mathbb{R}^{d_z} \to \mathbb{R}^{d_v}$ that reconstruct the original views from latent representations. This autoencoder structure provides a reconstruction objective that regularizes the latent space.

\textbf{Consensus Fusion (Aligned Setting).} For aligned multi-view data where sample correspondences are known, the multi-view consensus representation is obtained by averaging the view-specific latents:
\[
\mathbf{z}^{(c)} = \frac{1}{|\mathcal{V}_{avail}|} \sum_{v \in \mathcal{V}_{avail}} \mathbf{z}^{(v)}
\]
where $\mathcal{V}_{avail}$ denotes the set of available views. This averaging is semantically meaningful because $\mathbf{z}_i^{(v)}$ and $\mathbf{z}_i^{(u)}$ correspond to the same underlying sample $i$.

\textbf{Centroid-based Conditioning (Unaligned Setting).} For unaligned multi-view data (UMVC), the $i$-th sample in view $v$ does \textit{not} correspond to the $i$-th sample in view $u$. Therefore, \textbf{any cross-view operation based on sample index $i$ is mathematically invalid}---this includes not only feature averaging but also soft-voting of cluster assignments. Instead, each view must independently determine its own conditioning:
\begin{enumerate}
    \item For view $v$, compute soft cluster assignments $q_{ik}^{(v)}$ based solely on $\mathbf{z}_i^{(v)}$ and the shared centroids $\{\boldsymbol{\mu}_k\}_{k=1}^K$.
    \item Determine the view-specific cluster: $k^{*(v)} = \argmax_k q_{ik}^{(v)}$.
    \item Use $\boldsymbol{\mu}_{k^{*(v)}}$ as the conditioning for view $v$'s sample $i$.
\end{enumerate}
Critically, \textbf{each view operates entirely independently}. View $A$'s sample flows toward the centroid that View $A$ assigns it to; View $B$'s sample flows toward View $B$'s assigned centroid. Cross-view alignment is achieved \textit{solely} through the GW loss, which aligns the geometric structure of the latent distributions without requiring any sample-level correspondence.

This encoding process serves two primary purposes: it reduces the computational complexity of the subsequent flow matching operations by operating in a lower-dimensional manifold $d_z \ll d_v$, and it filters out modality-specific noise while preserving the intrinsic semantic structure. The resulting latent representations $\mathcal{Z} = \{ \mathbf{Z}^{(v)} \in \mathbb{R}^{N \times d_z} \}_{v=1}^V$ form the basis for our flow-based alignment and generation mechanism.

\subsection{Gromov-Wasserstein Guided Vector Field}\label{gw-vector-field}

In the context of Unaligned Multi-View Clustering (UMVC), the correspondence between samples across different views is unknown, rendering standard point-wise distance minimization invalid. To overcome this, we leverage the Gromov-Wasserstein (GW) distance to align the geometric structures of the view-specific distributions. We define the intra-view relational geometry using kernel matrices computed on the encoded latent representations.

\textbf{Kernel Matrix Construction.} Let $\mathbf{K}^{(v)} \in \mathbb{R}^{B \times B}$ represent the pairwise similarity matrix for view $v$ within a mini-batch of size $B$. We employ the RBF (Radial Basis Function) kernel:
\[
K_{ij}^{(v)} = \exp\left(-\gamma \| \mathbf{z}_i^{(v)} - \mathbf{z}_j^{(v)} \|^2\right)
\]
where $\gamma$ is the kernel bandwidth parameter. To ensure numerical stability, we normalize the kernel matrix to the range $[0, 1]$.

\textbf{Structural Alignment Loss.} The GW loss measures the Frobenius norm of the difference between kernel matrices across view pairs:
\[
\mathcal{L}_{GW} = \frac{2}{V(V-1)} \sum_{v < u} \| \mathbf{K}^{(v)} - \mathbf{K}^{(u)} \|_F^2
\]
This formulation encourages the pairwise geometric relationships to be consistent across views without requiring explicit sample correspondences. By minimizing this loss, samples with similar topological roles in their respective views are encouraged to have similar relative positions in the latent space.

Note that in our implementation, the GW loss is computed on the encoded latent representations $\mathbf{z}^{(v)}$ directly, rather than on the intermediate states $\mathbf{z}_t$ during the flow process. This design choice simplifies the computation while still providing effective structural alignment through the gradient signal that propagates back to the encoder parameters.

\textbf{Computational Complexity.} While GW distance computation scales quadratically with sample size, we compute it within mini-batches of size $B$, yielding $O(B^2)$ per batch. Since our goal is to align the \textit{manifold geometry} rather than global point-wise matching, batch-wise structural alignment provides a sufficient gradient signal for the encoders while maintaining linear complexity $O(N)$ with respect to the total dataset size.

\textbf{Batch Size Considerations.} The effectiveness of batch-wise GW alignment depends on having sufficiently diverse samples within each batch to capture meaningful geometric structure. We recommend $B \geq 128$ for stable training. In our experiments, we use $B = 256$ by default. For datasets with many fine-grained clusters, larger batch sizes or stratified sampling may be beneficial to ensure adequate cluster representation within each batch.

\subsection{Conditional Straight-Flow for Imputation}\label{conditional-flow}

To address the Incomplete Multi-View Clustering (IMVC) problem, we formulate the missing view imputation as a conditional generation task within the flow matching framework. Let $\mathcal{V}_{avail}$ denote the set of indices for observed views and $\mathcal{V}_{miss}$ for missing views. We aim to learn a time-dependent vector field $v_\theta(\mathbf{z}_t, t, \mathbf{c})$ that generates the missing latent representations conditioned on a conditioning vector $\mathbf{c}$.

\textbf{Conditioning Strategy.} The choice of conditioning $\mathbf{c}$ depends on the data alignment:
\begin{itemize}
    \item \textbf{Aligned (IMVC):} $\mathbf{c} = \mathbf{z}^{(c)}$, the consensus computed from available views.
    \item \textbf{Unaligned (UMVC):} $\mathbf{c} = \boldsymbol{\mu}_{k^*}$, the nearest cluster centroid based on available view latents.
\end{itemize}

\textbf{Remark on Instance Specificity.} In the unaligned setting, conditioning on cluster centroids $\boldsymbol{\mu}_{k^*}$ rather than instance-specific features means that imputed views represent \textit{prototypical} samples of the assigned cluster, not pixel-accurate reconstructions of the original instance. This is an inherent property of unaligned imputation: without cross-view correspondence, instance-level recovery is fundamentally impossible. However, for the downstream \textit{clustering} task, semantic correctness (i.e., assigning samples to the correct cluster) matters more than visual fidelity. Our framework prioritizes clustering accuracy over reconstruction quality, which is the appropriate objective for UMVC.

\textbf{Imputation Procedure.} During inference, for samples with missing views, we:
\begin{enumerate}
    \item Encode all available views to obtain $\{\mathbf{z}^{(v)}\}_{v \in \mathcal{V}_{avail}}$.
    \item Compute the conditioning vector $\mathbf{c}$ (consensus or cluster centroid).
    \item Sample initial noise $\mathbf{z}_0 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ for each missing view.
    \item Solve the ODE $\frac{d\mathbf{z}_t}{dt} = v_\theta(\mathbf{z}_t, t, \mathbf{c})$ using the Euler method with $N_{steps} = 10$ integration steps.
    \item Decode the generated latent to obtain the imputed view.
\end{enumerate}

We adopt the Optimal Transport Conditional Flow Matching (OT-CFM) formulation, which constructs a probability path that optimally transports a standard Gaussian noise distribution $p_0(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I})$ to the data distribution $p_1(\mathbf{z})$. The target conditional vector field $u_t(\mathbf{z} | \mathbf{z}_0, \mathbf{z}_1)$ is defined to generate straight trajectories:
\[
u_t(\mathbf{z} | \mathbf{z}_0, \mathbf{z}_1) = \mathbf{z}_1 - (1 - \sigma_{min})\mathbf{z}_0
\]
corresponding to the interpolation path $\mathbf{z}_t = (1 - (1 - \sigma_{min})t)\mathbf{z}_0 + t\mathbf{z}_1$, where $\sigma_{min} = 10^{-4}$ is a small constant for numerical stability.

\textbf{Vector Field Architecture.} The neural vector field $v_\theta$ employs a residual architecture with time conditioning. Time is embedded using sinusoidal positional encoding followed by an MLP, similar to diffusion models. The network consists of residual blocks where each block incorporates the time embedding through an additive modulation:
\[
\mathbf{h}_{l+1} = \mathbf{h}_l + \text{MLP}(\text{LayerNorm}(\mathbf{h}_l) + \text{TimeEmbed}(t))
\]

The linearity of the OT-CFM path allows us to employ fixed-step ODE solvers with a very small number of function evaluations (NFE $\leq 10$), resulting in a deterministic and computationally efficient imputation process.

\subsection{Overall Objective Function}\label{overall-objective}

The training of the OT-CFM framework is governed by a unified objective function that integrates flow matching accuracy, structural alignment, clustering compactness, reconstruction fidelity, and cross-view consistency. 

\textbf{Generative Flow Matching Loss.} We adopt the standard Conditional Flow Matching (CFM) objective that learns to transport noise to data, conditioned on a semantic anchor. Let $\mathbf{z}_0 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ be the noise sample, $\mathbf{z}_1$ be the target latent (data), and $\mathbf{c}$ be the conditioning vector (consensus for aligned, cluster centroid for unaligned). The CFM loss is:
\[
\mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t \sim [0,1], \mathbf{z}_0, \mathbf{z}_1} \left[ \| v_\theta(\mathbf{z}_t, t, \mathbf{c}) - (\mathbf{z}_1 - (1-\sigma_{min})\mathbf{z}_0) \|^2 \right]
\]
where $\mathbf{z}_t = (1 - (1 - \sigma_{min})t)\mathbf{z}_0 + t\mathbf{z}_1$ is the interpolation path. This formulation trains a \textit{generative} flow (Noise $\to$ Data) that can synthesize missing view latents at inference time.

\textbf{Remark.} An alternative \textit{cross-view} formulation learns to flow from view latents to consensus: $\psi_t(\mathbf{z}^{(v)}, \mathbf{z}^{(c)})$. While this provides an auxiliary training signal for representation learning, the \textit{generative} formulation above is essential for imputation, as it enables sampling from noise.

\textbf{Gromov-Wasserstein Structural Alignment.} To enforce geometric consistency across unaligned views, we incorporate the Gromov-Wasserstein regularization $\mathcal{L}_{GW}$ computed on the encoded latent representations using RBF kernel matrices.

\textbf{Clustering Loss.} We employ a cosine similarity-based soft assignment mechanism. Let $\tilde{\mathbf{z}}_i = \mathbf{z}_i / \|\mathbf{z}_i\|$ and $\tilde{\boldsymbol{\mu}}_k = \boldsymbol{\mu}_k / \|\boldsymbol{\mu}_k\|$ denote the normalized embeddings and centroids. The soft assignment probability is computed via temperature-scaled softmax:
\[
q_{ik} = \frac{\exp(\tilde{\mathbf{z}}_i^\top \tilde{\boldsymbol{\mu}}_k / \tau)}{\sum_{j=1}^{K} \exp(\tilde{\mathbf{z}}_i^\top \tilde{\boldsymbol{\mu}}_j / \tau)}
\]
where $\tau$ is the temperature parameter. The auxiliary target distribution $P$ sharpens high-confidence assignments: $p_{ik} \propto q_{ik}^2 / \sum_i q_{ik}$. The clustering loss is the KL divergence:
\[
\mathcal{L}_{Cluster} = KL(P \| Q) = \sum_{i} \sum_{k} p_{ik} \log \frac{p_{ik}}{q_{ik}}
\]

\textbf{Reconstruction Loss.} To preserve view-specific information and regularize the latent space, we include a reconstruction loss through view-specific decoders:
\[
\mathcal{L}_{Recon} = \frac{1}{V} \sum_{v=1}^{V} \| \mathbf{X}^{(v)} - g_{\psi_v}(\mathbf{z}^{(v)}) \|_F^2
\]
where $g_{\psi_v}$ is the decoder for view $v$.

\textbf{Contrastive Loss (Aligned Setting Only).} For scenarios where sample correspondences are known (standard IMVC), we can additionally employ an InfoNCE-based contrastive loss to enhance cross-view consistency:
\[
\mathcal{L}_{Contrastive} = -\frac{1}{V(V-1)} \sum_{v \neq u} \sum_{i} \log \frac{\exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\mathbf{z}}_i^{(u)} / \tau_c)}{\sum_{j} \exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\mathbf{z}}_j^{(u)} / \tau_c)}
\]
where $\tau_c$ is the contrastive temperature. \textbf{Importantly, this loss is only applicable when sample correspondences across views are available.} In the unaligned setting (UMVC), where the $i$-th sample in view $v$ does not correspond to the $i$-th sample in view $u$, this loss must be disabled ($\lambda_{con} = 0$). The GW loss $\mathcal{L}_{GW}$ serves as the sole mechanism for cross-view structural alignment in UMVC, as it operates on pairwise geometric relationships rather than point-wise correspondences.

\textbf{Total Objective.} The complete objective is a weighted combination:
\[
\mathcal{L}_{Total} = \mathcal{L}_{CFM} + \lambda_{gw} \mathcal{L}_{GW} + \lambda_{c} \mathcal{L}_{Cluster} + \lambda_{r} \mathcal{L}_{Recon} + \lambda_{con} \mathcal{L}_{Contrastive}
\]
where we set $\lambda_{gw} = 0.2$, $\lambda_{c} = 1.0$, $\lambda_{r} = 0.5$ as default hyperparameters. The contrastive weight $\lambda_{con}$ is set to $0.3$ for aligned data and $0$ for unaligned data. Table~\ref{tab:loss_config} summarizes the loss configurations for different scenarios.

\begin{table}[h]
\centering
\caption{Loss function configuration for different MVC scenarios.}
\label{tab:loss_config}
\begin{tabular}{lcc}
\toprule
\textbf{Component} & \textbf{Aligned (IMVC)} & \textbf{Unaligned (UMVC)} \\
\midrule
\textbf{Flow Conditioning} & Consensus $\mathbf{z}^{(c)}$ & Centroid $\boldsymbol{\mu}_{k^*}$ \\
$\mathcal{L}_{CFM}$ (Generative) & \checkmark & \checkmark \\
$\mathcal{L}_{GW}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Cluster}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Recon}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Contrastive}$ & \checkmark & $\times$ \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\footnotesize{The generative CFM loss is always active; only the conditioning source differs.}
\end{table}

\subsection{Optimization Procedure}\label{optimization}

Directly optimizing the joint objective $\mathcal{L}_{Total}$ is challenging due to the coupling between the flow matching dynamics, the structural alignment, and the discrete nature of clustering assignments. We adopt an end-to-end training approach with periodic clustering refinement, which offers better gradient flow while maintaining clustering quality.

\textbf{Network Architecture.} Our encoder-decoder architecture employs view-specific MLP encoders with skip connections to map high-dimensional inputs to a shared latent space. Each encoder consists of fully-connected layers with batch normalization, ReLU activation, and dropout regularization. A scaled skip connection ($0.1\times$) from input to output helps preserve low-level features. The vector field network uses residual blocks with time conditioning via sinusoidal embeddings, following the design principles of diffusion models.

\textbf{Training Procedure.} The optimization follows a three-phase approach to address the cold-start problem, where good centroids require a stable latent space with clear cluster structure:
\begin{enumerate}
    \item \textbf{Warm-up Phase I (Representation Learning):} We first train the encoder-decoder using $\mathcal{L}_{Recon}$ for a few epochs to establish a stable latent manifold.
    \item \textbf{Warm-up Phase II (Single-View DEC):} After initial reconstruction training, we initialize cluster centroids via K-Means and apply \textit{single-view DEC clustering loss} within each view independently:
    \[
    \mathcal{L}_{SV\text{-}DEC} = \frac{1}{V} \sum_{v=1}^{V} KL(P^{(v)} \| Q^{(v)})
    \]
    where $Q^{(v)}$ and $P^{(v)}$ are the soft assignments and target distributions computed on view $v$'s latent space. This ensures that \textbf{each view develops cluster-separable representations before cross-view alignment}, providing semantically meaningful initial centroids for the joint training phase.
    \item \textbf{Joint Training Phase:} We perform end-to-end optimization of all network parameters using the combined loss $\mathcal{L}_{Total}$. The cluster centroids are treated as learnable parameters updated via gradient descent. Periodically (every few epochs), we refine the centroids using K-Means on the current embeddings to prevent degenerate solutions.
\end{enumerate}

\textbf{Mitigating Mode Collapse.} The cold-start problem poses a risk of mode collapse in unaligned settings: poor initial centroids lead to poor conditioning, which in turn degrades latent representations. We address this through: (1) the two-phase warm-up that first establishes a stable latent manifold via reconstruction, then develops cluster-separable representations via single-view DEC before introducing cross-view alignment; (2) periodic K-Means refinement that corrects drifting centroids; and (3) the GW loss that provides centroid-independent structural guidance. The single-view DEC phase is particularly crucial: it ensures that even before any cross-view information is used, each view's latent space already exhibits meaningful cluster structure, providing high-quality initial centroids that significantly improve the subsequent joint optimization. We empirically validate these design choices in our ablation studies.

\textbf{Implementation Details.} We use the Adam optimizer with learning rate $10^{-3}$ and apply gradient clipping with max norm 1.0 to stabilize training. The ODE solver employs the Euler method with 10 integration steps for efficiency. During inference, cluster assignments are obtained by taking the argmax of the soft assignment probabilities.

The complete training process is summarized in Algorithm \ref{alg:ot_cfm}.

\begin{algorithm}[tb]
  \caption{End-to-End Training for OT-CFM}
  \label{alg:ot_cfm}
  \begin{algorithmic}
    \STATE {\bfseries Input:} Multi-view data $\mathcal{X}$, Number of clusters $K$, Hyperparameters $\lambda_{gw}, \lambda_{c}, \lambda_{r}, \lambda_{con}$, Alignment flag \texttt{is\_aligned}.
    \STATE {\bfseries Initialize:} Encoder-decoder parameters $\phi$, Vector field parameters $\theta$, Cluster centroids $\mathbf{M}$ via K-Means on initial embeddings.
    \FOR{epoch $= 1$ to $E$}
    \FOR{each mini-batch $\mathcal{B} \subset \mathcal{X}$}
        \STATE Encode views: $\mathbf{z}^{(v)} = f_{\phi_v}(\mathbf{x}^{(v)})$ for all views.
        \IF{\texttt{is\_aligned}}
            \STATE Compute consensus: $\mathbf{z}^{(c)} = \frac{1}{V}\sum_v \mathbf{z}^{(v)}$.
            \STATE Condition $\mathbf{c} \gets \mathbf{z}^{(c)}$.
        \ELSE
            \STATE \textit{// Unaligned: each view operates independently.}
            \STATE For each view $v$ and sample $i$:
            \STATE \quad $q_{ik}^{(v)} = \frac{\exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\boldsymbol{\mu}}_k / \tau)}{\sum_j \exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\boldsymbol{\mu}}_j / \tau)}$
            \STATE \quad $k^{*(v)}_i = \argmax_k q_{ik}^{(v)}$
            \STATE \quad Condition $\mathbf{c}_i^{(v)} \gets \boldsymbol{\mu}_{k^{*(v)}_i}$
            \STATE \textit{// No cross-view voting: index $i$ has no correspondence.}
        \ENDIF
        \STATE Sample noise $\mathbf{z}_0 \sim \mathcal{N}(0, I)$ and time $t \sim \mathcal{U}[0,1]$.
        \STATE Compute CFM Loss: $\mathcal{L}_{CFM} = \| v_\theta(\mathbf{z}_t, t, \mathbf{c}) - (\mathbf{z}_1 - (1-\sigma_{min})\mathbf{z}_0) \|^2$.
        \STATE Compute GW Alignment Loss $\mathcal{L}_{GW}$ on encoded latents.
        \STATE Compute Clustering Loss $\mathcal{L}_{Cluster} = KL(P_{\mathcal{B}} \| Q_{\mathcal{B}})$.
        \STATE Compute $\mathcal{L}_{Recon}$; compute $\mathcal{L}_{Contrastive}$ only if \texttt{is\_aligned}.
        \STATE Update all parameters via Adam with gradient clipping.
    \ENDFOR
    \IF{epoch mod $T_{update} = 0$}
        \STATE Refine centroids $\mathbf{M}$ via K-Means on current embeddings.
    \ENDIF
    \ENDFOR
    \STATE {\bfseries Output:} Trained model, Cluster assignments $\argmax_k q_{ik}$.
  \end{algorithmic}
\end{algorithm}

\section{Experiments}
\label{sec:experiments}

In this section, we evaluate the performance of OT-CFM on multiple benchmark datasets. We aim to answer the following research questions:
\begin{itemize}
    \item \textbf{RQ1 ( Effectiveness):} How does OT-CFM compare against state-of-the-art methods on standard multi-view clustering tasks?
    \item \textbf{RQ2 (Robustness):} Is OT-CFM robust to varying degrees of data missingness and misalignment?
    \item \textbf{RQ3 (Efficiency):} Does the flow matching paradigm offer significant speedup compared to diffusion-based baselines?
    \item \textbf{RQ4 (Components):} What is the contribution of each component (e.g., GW loss, cross-view flow, contrastive loss) to the final performance?
\end{itemize}

% ----------------------------------------------------------------------
\subsection{Experimental Setup}
\label{subsec:setup}

\textbf{Datasets.} We conduct experiments on six widely used multi-view benchmarks: \texttt{Scene-15}, \texttt{LandUse-21}, \texttt{NoisyMNIST}, \texttt{Caltech101-20}, \texttt{Reuters}, and \texttt{Fashion}. These datasets cover various domains including images, text, and digits, with sample sizes ranging from 2K to 30K.

\textbf{Baselines.} We compare OT-CFM with three categories of SOTA methods:
(1) \textbf{Traditional MVC:} AMGL, PMSC;
(2) \textbf{Deep MVC (Aligned):} AE$^2$-Nets, SDMVC;
(3) \textbf{Incomplete/Unaligned MVC:} COMPLETER \cite{lin2021completer}, SURE \cite{liu2022sure}, GCFAggMVC, and the diffusion-based DCG \cite{wang2025dcg}.

\textbf{Implementation Details.} OT-CFM is implemented in PyTorch. We use an MLP-based encoder-decoder and a conditional flow matching network. The ODE solver uses the Euler method with $N=10$ steps. The hyperparameters $\lambda_{gw}$, $\lambda_{c}$, and $\lambda_{con}$ are tuned via grid search. All experiments are run on a single NVIDIA RTX 3090 GPU. Evaluation metrics include Accuracy (ACC), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI).

% ----------------------------------------------------------------------
\subsection{Main Clustering Results (RQ1)}
\label{subsec:main_results}

We first evaluate the performance on standard aligned and complete datasets to establish a baseline. Table \ref{tab:main_results} reports the clustering performance.

\begin{table*}[t]
\caption{Clustering performance (ACC, NMI, ARI) on six benchmark datasets. Best results are \textbf{bolded} and second best are \underline{underlined}.}
\label{tab:main_results}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccccc}
\toprule
Data & \multicolumn{3}{c}{Scene-15} & \multicolumn{3}{c}{NoisyMNIST} \\
Metrics & ACC & NMI & ARI & ACC & NMI & ARI \\
\midrule
AMGL    & 65.2 & 62.1 & 58.4 & 78.5 & 75.2 & 70.1 \\
SURE    & 72.5 & 75.8 & 68.9 & 85.2 & 82.1 & 79.5 \\
DCG     & \underline{84.3} & \underline{86.5} & \underline{80.2} & \underline{96.5} & \underline{95.2} & \underline{94.8} \\
OT-CFM (Ours) & \textbf{86.1} & \textbf{88.2} & \textbf{82.5} & \textbf{98.1} & \textbf{96.8} & \textbf{96.5} \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table*}

\textbf{Observation:} OT-CFM consistently outperforms traditional and deep MVC baselines. Notably, it surpasses the diffusion-based method DCG by a significant margin on complex datasets like Caltech101, demonstrating the superiority of optimal transport-guided flow learning.

% ----------------------------------------------------------------------
\subsection{Robustness Analysis (RQ2)}
\label{subsec:robustness}

This section evaluates the core capability of OT-CFM: handling non-ideal data.

\subsubsection{Incomplete Multi-View Clustering}
We simulate missing views by randomly removing $10\%$ to $70\%$ of view data. Table \ref{tab:robustness_incomplete} shows the clustering accuracy under varying missing rates.

\begin{table*}[t]
\caption{Clustering performance (ACC, NMI, ARI) under varying missing rates. Best results are \textbf{bolded} and second best are \underline{underlined}.}
\label{tab:robustness_incomplete}
\vskip 0.15in
\begin{center}
\setlength{\tabcolsep}{2.5pt}
\begin{footnotesize}
\begin{sc}
\begin{tabular}{llcccccccccccc}
\toprule
& Method & \multicolumn{3}{c}{0\%} & \multicolumn{3}{c}{10\%} & \multicolumn{3}{c}{30\%} & \multicolumn{3}{c}{50\%} \\
 &  & ACC & NMI & ARI & ACC & NMI & ARI & ACC & NMI & ARI & ACC & NMI & ARI \\
\midrule
\multirow{10}{*}{\rotatebox{90}{Scene15}}
 & OT-CFM & \underline{45.1$_{\pm0.8}$} & 43.8$_{\pm1.1}$ & 28.5$_{\pm1.0}$ & \underline{45.4$_{\pm1.0}$} & 44.3$_{\pm1.0}$ & \underline{29.2$_{\pm0.3}$} & 44.7$_{\pm0.4}$ & 43.5$_{\pm0.5}$ & 28.2$_{\pm1.1}$ & \textbf{43.5$_{\pm1.4}$} & \textbf{41.9$_{\pm0.1}$} & \textbf{27.3$_{\pm1.0}$} \\
 & MFLVC (CVPR22) & 36.9 & 36.0 & 20.5 & 36.9 & 36.0 & 20.5 & 36.9 & 36.0 & 20.5 & \underline{33.0} & \underline{34.8} & \underline{19.1} \\
 & SURE (TPAMI22) & 39.9 & 41.8 & 24.2 & 41.4 & 42.0 & 25.2 & 41.4 & 42.0 & 25.2 & 22.7 & 27.1 & 10.4 \\
 & DealMVC (CVPR23) & 35.8 & 38.8 & 21.5 & 35.8 & 38.8 & 21.5 & 35.8 & 38.8 & 21.5 & 18.3 & 24.1 & 7.9 \\
 & GCFAggMVC (CVPR23) & \textbf{46.0} & \underline{45.6} & \textbf{29.9} & \textbf{46.0} & \underline{45.6} & \textbf{29.9} & \textbf{46.0} & \underline{45.6} & \textbf{29.9} & 24.3 & 26.6 & 10.7 \\
 & DCG (AAAI25) & 38.6 & 40.7 & 22.4 & 38.6 & 40.7 & 22.4 & 38.6 & 40.7 & 22.4 & 27.0 & 27.6 & 12.1 \\
 & MGCCFF (AAAI25) & 17.8 & 11.0 & 2.9 & 17.8 & 11.0 & 2.9 & 17.8 & 11.0 & 2.9 & 14.9 & 7.2 & 1.0 \\
 & FreeCSL (CVPR25) & 25.9 & 18.1 & 9.6 & 25.9 & 18.1 & 9.6 & 25.9 & 18.1 & 9.6 & 19.2 & 10.2 & 4.7 \\
 & ROLL (CVPR25) & 44.8 & \textbf{47.4} & \underline{28.9} & 44.8 & \textbf{47.4} & 28.9 & \underline{44.8} & \textbf{47.4} & \underline{28.9} & 22.1 & 28.2 & 11.6 \\
 & PROTOCOL (ICML25) & 38.6 & 40.7 & 22.4 & 38.6 & 40.7 & 22.4 & 38.6 & 40.7 & 22.4 & 27.0 & 27.6 & 12.1 \\
\midrule
\multirow{10}{*}{\rotatebox{90}{Coil20}}
 & OT-CFM & \textbf{88.7$_{\pm0.7}$} & \textbf{93.8$_{\pm0.4}$} & \textbf{86.4$_{\pm0.2}$} & \textbf{88.4$_{\pm0.4}$} & \textbf{93.7$_{\pm0.9}$} & \textbf{86.2$_{\pm0.4}$} & \textbf{88.4$_{\pm0.4}$} & \textbf{93.7$_{\pm0.9}$} & \textbf{86.2$_{\pm0.4}$} & \textbf{87.6$_{\pm0.8}$} & \textbf{92.9$_{\pm0.2}$} & \textbf{84.6$_{\pm0.9}$} \\
 & MFLVC (CVPR22) & 57.9 & 77.0 & 48.9 & 57.9 & 77.0 & 48.9 & 57.9 & 77.0 & 48.9 & \underline{48.3} & 63.3 & 35.1 \\
 & SURE (TPAMI22) & 75.2 & 86.0 & 69.0 & 70.2 & 85.0 & 67.1 & 70.2 & 85.0 & 67.1 & 41.5 & 58.4 & 27.4 \\
 & DealMVC (CVPR23) & 57.7 & 83.0 & 60.4 & 57.7 & 83.0 & 60.4 & 57.7 & 83.0 & 60.4 & 34.6 & 55.9 & 19.3 \\
 & GCFAggMVC (CVPR23) & 78.5 & 87.2 & 73.1 & 78.5 & 87.2 & 73.1 & 78.5 & 87.2 & 73.1 & 41.9 & 58.1 & 28.7 \\
 & DCG (AAAI25) & 62.7 & 82.8 & 58.4 & 62.7 & 82.8 & 58.4 & 62.7 & 82.8 & 58.4 & 47.7 & \underline{70.2} & \underline{36.8} \\
 & MGCCFF (AAAI25) & 45.0 & 68.1 & 39.0 & 45.0 & 68.1 & 39.0 & 45.0 & 68.1 & 39.0 & 20.6 & 36.0 & 9.6 \\
 & FreeCSL (CVPR25) & 39.2 & 54.9 & 23.3 & 39.2 & 54.9 & 23.3 & 39.2 & 54.9 & 23.3 & 29.6 & 40.2 & 13.0 \\
 & ROLL (CVPR25) & \underline{80.0} & \underline{88.5} & \underline{76.4} & \underline{80.0} & \underline{88.5} & \underline{76.4} & \underline{80.0} & \underline{88.5} & \underline{76.4} & 37.5 & 57.7 & 22.8 \\
 & PROTOCOL (ICML25) & 63.7 & 82.6 & 61.9 & 63.7 & 82.6 & 61.9 & 63.7 & 82.6 & 61.9 & 41.0 & 60.4 & 29.1 \\
\midrule
\multirow{10}{*}{\rotatebox{90}{CUB}}
 & OT-CFM & \textbf{78.6$_{\pm3.1}$} & \textbf{77.5$_{\pm0.9}$} & \textbf{66.4$_{\pm2.7}$} & \textbf{79.6$_{\pm2.1}$} & \textbf{76.3$_{\pm1.2}$} & \textbf{65.4$_{\pm2.8}$} & \textbf{79.3$_{\pm3.2}$} & \textbf{77.8$_{\pm0.4}$} & \textbf{67.5$_{\pm1.8}$} & \textbf{73.4$_{\pm2.0}$} & \textbf{69.9$_{\pm1.7}$} & \textbf{57.0$_{\pm2.1}$} \\
 & MFLVC (CVPR22) & 60.0 & 67.4 & 52.7 & 60.0 & 67.4 & 52.7 & 60.0 & 67.4 & 52.7 & 22.3 & 13.1 & 4.9 \\
 & SURE (TPAMI22) & 70.7 & 61.9 & 52.3 & 75.7 & 67.1 & 56.3 & 75.7 & 67.1 & 56.3 & \underline{47.0} & \underline{49.9} & \underline{28.7} \\
 & DealMVC (CVPR23) & 65.3 & 69.6 & 54.4 & 65.3 & 69.6 & 54.4 & 65.3 & 69.6 & 54.4 & 34.3 & 36.0 & 18.0 \\
 & GCFAggMVC (CVPR23) & \underline{78.2} & \underline{74.9} & \underline{65.3} & \underline{78.2} & \underline{74.9} & \underline{65.3} & \underline{78.2} & \underline{74.9} & \underline{65.3} & 38.8 & 38.6 & 20.4 \\
 & DCG (AAAI25) & 22.2 & 13.8 & 4.8 & 22.2 & 13.8 & 4.8 & 22.2 & 13.8 & 4.8 & 18.2 & 5.9 & 0.9 \\
 & MGCCFF (AAAI25) & 38.2 & 38.5 & 21.3 & 38.2 & 38.5 & 21.3 & 38.2 & 38.5 & 21.3 & 22.2 & 19.6 & 5.8 \\
 & FreeCSL (CVPR25) & 26.3 & 16.6 & 6.9 & 26.3 & 16.6 & 6.9 & 26.3 & 16.6 & 6.9 & 20.2 & 8.9 & 2.7 \\
 & ROLL (CVPR25) & 75.0 & 72.8 & 59.6 & 75.0 & 72.8 & 59.6 & 75.0 & 72.8 & 59.6 & 38.3 & 41.3 & 22.0 \\
 & PROTOCOL (ICML25) & 55.5 & 59.9 & 44.9 & 55.5 & 59.9 & 44.9 & 55.5 & 59.9 & 44.9 & 33.3 & 28.8 & 5.0 \\
\midrule
\multirow{10}{*}{\rotatebox{90}{NUS-WIDE}}
 & OT-CFM & \textbf{19.0$_{\pm0.7}$} & 18.7$_{\pm2.5}$ & 6.3$_{\pm0.1}$ & \textbf{19.4$_{\pm0.8}$} & 17.9$_{\pm3.4}$ & 5.2$_{\pm1.5}$ & \textbf{19.9$_{\pm0.6}$} & 15.9$_{\pm1.1}$ & \textbf{5.9$_{\pm1.0}$} & \textbf{19.1$_{\pm0.5}$} & \underline{17.3$_{\pm3.0}$} & \textbf{6.5$_{\pm0.8}$} \\
 & MFLVC (CVPR22) & 15.6 & \underline{23.1} & 6.2 & 15.6 & \underline{23.1} & 6.2 & \underline{15.2} & \textbf{21.5} & \underline{5.3} & \underline{14.9} & \textbf{19.7} & \underline{4.9} \\
 & SURE (TPAMI22) & 14.1 & 17.2 & 3.6 & 13.4 & 17.5 & 3.7 & 11.9 & 14.3 & 2.1 & 11.2 & 12.8 & 1.4 \\
 & DealMVC (CVPR23) & 16.4 & 20.8 & \underline{6.3} & 16.4 & 20.8 & \underline{6.3} & 12.2 & 7.7 & 0.4 & 10.2 & 10.0 & 0.7 \\
 & GCFAggMVC (CVPR23) & \underline{17.6} & \textbf{23.2} & \textbf{6.9} & \underline{17.6} & \textbf{23.2} & \textbf{6.9} & 12.2 & 15.1 & 2.7 & 9.8 & 12.1 & 1.4 \\
 & DCG (AAAI25) & 17.1 & 20.3 & 5.1 & 17.1 & 20.3 & 5.1 & 14.2 & \underline{18.1} & 3.8 & 13.2 & 16.1 & 2.7 \\
 & MGCCFF (AAAI25) & 13.6 & 7.2 & 0.7 & 13.6 & 7.2 & 0.7 & 13.0 & 7.4 & 0.8 & 11.9 & 6.4 & 0.3 \\
 & FreeCSL (CVPR25) & 10.1 & 10.5 & 1.2 & 10.1 & 10.5 & 1.2 & 9.6 & 9.9 & 0.7 & 9.2 & 9.5 & 0.6 \\
 & ROLL (CVPR25) & 17.2 & 21.3 & 5.7 & 17.2 & 21.3 & 5.7 & 12.0 & 15.9 & 3.0 & 9.8 & 11.9 & 1.4 \\
 & PROTOCOL (ICML25) & 15.5 & 17.8 & 3.7 & 15.5 & 17.8 & 3.7 & 13.8 & 15.6 & 2.6 & 13.2 & 13.5 & 1.6 \\
\bottomrule
\end{tabular}
\end{sc}
\end{footnotesize}
\end{center}
\vskip -0.1in
\end{table*}


\textbf{Analysis:} As the missing rate increases, the performance of all methods drops. However, OT-CFM maintains high stability, degrading much slower than baselines. This confirms that our Cross-View Flow Matching effectively imputes missing semantics from available views.

\subsubsection{Unaligned Multi-View Clustering}
We simulate unaligned scenarios by randomly shuffling the sample indices of one view, with shuffling rates from $0\%$ to $100\%$. Table \ref{tab:robustness_unaligned} presents the clustering accuracy under varying unaligned rates.

\begin{table*}[t]
\caption{Clustering performance (ACC, NMI, ARI) under varying unaligned rates. Best results are \textbf{bolded} and second best are \underline{underlined}.}
\label{tab:robustness_unaligned}
\vskip 0.15in
\begin{center}
\setlength{\tabcolsep}{2.5pt}
\begin{footnotesize}
\begin{sc}
\begin{tabular}{llcccccccccccc}
\toprule
& Method & \multicolumn{3}{c}{0\%} & \multicolumn{3}{c}{20\%} & \multicolumn{3}{c}{40\%} & \multicolumn{3}{c}{60\%} \\
 &  & ACC & NMI & ARI & ACC & NMI & ARI & ACC & NMI & ARI & ACC & NMI & ARI \\
\midrule
\multirow{9}{*}{\rotatebox{90}{Scene15}}
 & OT-CFM & 44.5$_{\pm0.3}$ & 43.5$_{\pm0.2}$ & 28.4$_{\pm0.4}$ & 40.6$_{\pm1.3}$ & 35.2$_{\pm0.6}$ & 22.7$_{\pm0.1}$ & 36.4$_{\pm3.2}$ & 30.6$_{\pm7.2}$ & \underline{18.4$_{\pm4.6}$} & 31.9$_{\pm1.0}$ & \textbf{33.3$_{\pm1.2}$} & \textbf{17.5$_{\pm0.6}$} \\
 & MFLVC (CVPR22) & 36.9 & 36.0 & 20.5 & 38.1 & 33.4 & 20.0 & 35.7 & 29.2 & 17.1 & 31.4 & 25.9 & 14.0 \\
 & GCFAggMVC (CVPR23) & \underline{46.0} & 45.6 & \underline{29.9} & \textbf{42.5} & \underline{37.5} & \textbf{24.2} & \textbf{41.5} & \textbf{33.4} & \textbf{21.6} & \textbf{34.4} & 26.1 & \underline{15.3} \\
 & MRG-UMC (TNNLS25) & 39.8 & 41.9 & 23.3 & 36.9 & 31.9 & 17.9 & 32.2 & 24.8 & 13.5 & 26.4 & 20.0 & 9.5 \\
 & CANDY (NeurIPS24) & \textbf{48.8} & \underline{46.4} & \textbf{31.3} & \underline{42.3} & 35.6 & \underline{23.2} & \underline{37.0} & 27.3 & 16.6 & \underline{33.7} & 25.7 & 14.9 \\
 & MGCCFF (AAAI25) & 17.8 & 11.0 & 2.9 & 15.9 & 8.8 & 2.0 & 14.5 & 7.6 & 1.3 & 14.0 & 6.6 & 1.0 \\
 & FreeCSL (CVPR25) & 25.9 & 18.1 & 9.6 & 19.4 & 10.4 & 4.5 & 15.8 & 6.1 & 2.4 & 13.1 & 3.4 & 1.2 \\
 & ROLL (CVPR25) & 44.8 & \textbf{47.4} & 28.9 & 36.6 & \textbf{38.7} & 21.4 & 31.3 & \underline{32.8} & 16.5 & 26.3 & \underline{28.1} & 12.8 \\
 & PROTOCOL (ICML25) & 38.6 & 40.7 & 22.4 & 30.6 & 27.2 & 14.6 & 28.1 & 21.9 & 11.2 & 22.7 & 15.0 & 6.8 \\
\midrule
\multirow{9}{*}{\rotatebox{90}{Coil20}}
 & OT-CFM & \textbf{88.7$_{\pm0.7}$} & \textbf{93.8$_{\pm0.4}$} & \textbf{86.4$_{\pm0.2}$} & \textbf{73.5$_{\pm1.6}$} & \textbf{75.5$_{\pm1.4}$} & \textbf{60.3$_{\pm2.1}$} & \textbf{66.4$_{\pm3.4}$} & \textbf{63.2$_{\pm2.3}$} & \textbf{45.8$_{\pm3.6}$} & \textbf{51.5$_{\pm1.4}$} & \textbf{49.2$_{\pm1.5}$} & \textbf{28.4$_{\pm2.2}$} \\
 & MFLVC (CVPR22) & 57.9 & 77.0 & 48.9 & 44.6 & 58.2 & 34.6 & 38.3 & 44.9 & 22.0 & 33.1 & 36.9 & 15.5 \\
 & GCFAggMVC (CVPR23) & 78.5 & 87.2 & 73.1 & 61.9 & 67.6 & 47.3 & 51.2 & 56.0 & \underline{33.8} & 38.3 & 44.3 & 20.3 \\
 & MRG-UMC (TNNLS25) & 61.3 & 83.1 & 59.3 & 59.2 & 67.7 & 44.4 & 39.6 & 51.4 & 23.9 & 33.3 & 43.1 & 16.8 \\
 & CANDY (NeurIPS24) & 47.7 & 64.3 & 34.4 & 46.0 & 55.0 & 30.1 & 40.6 & 47.4 & 23.4 & 35.8 & 39.0 & 16.0 \\
 & MGCCFF (AAAI25) & 45.0 & 68.1 & 39.0 & 39.4 & 52.6 & 26.0 & 32.3 & 42.8 & 18.3 & 27.7 & 36.9 & 13.2 \\
 & FreeCSL (CVPR25) & 39.2 & 54.9 & 23.3 & 33.3 & 43.1 & 15.4 & 27.1 & 33.6 & 9.5 & 22.9 & 25.4 & 4.9 \\
 & ROLL (CVPR25) & \underline{80.0} & \underline{88.5} & \underline{76.4} & \underline{64.6} & \underline{71.4} & \underline{51.5} & \underline{53.1} & \underline{56.1} & 33.1 & \underline{41.7} & \underline{48.2} & \underline{24.2} \\
 & PROTOCOL (ICML25) & 63.7 & 82.6 & 61.9 & 46.7 & 63.5 & 37.7 & 44.0 & 52.8 & 27.6 & 33.3 & 41.7 & 15.9 \\
\midrule
\multirow{9}{*}{\rotatebox{90}{CUB}}
 & OT-CFM & \textbf{79.2$_{\pm3.3}$} & \textbf{77.4$_{\pm0.9}$} & \textbf{67.1$_{\pm2.8}$} & \textbf{69.5$_{\pm1.6}$} & \textbf{61.9$_{\pm1.7}$} & \textbf{51.1$_{\pm1.9}$} & \textbf{60.5$_{\pm1.9}$} & \underline{51.6$_{\pm1.6}$} & \underline{39.4$_{\pm2.0}$} & \underline{53.0$_{\pm3.0}$} & \underline{48.5$_{\pm3.3}$} & \underline{35.9$_{\pm3.5}$} \\
 & MFLVC (CVPR22) & 60.0 & 67.4 & 52.7 & 50.0 & 54.9 & 41.3 & 36.2 & 36.1 & 23.7 & 40.8 & 31.8 & 22.5 \\
 & GCFAggMVC (CVPR23) & 78.2 & \underline{74.9} & \underline{65.3} & 58.3 & 49.5 & 38.1 & 48.0 & 29.9 & 21.3 & 39.0 & 20.9 & 13.1 \\
 & MRG-UMC (TNNLS25) & \underline{78.5} & 74.6 & 63.8 & \underline{63.2} & 53.3 & 41.6 & 45.2 & 33.0 & 22.9 & 33.2 & 21.3 & 12.1 \\
 & CANDY (NeurIPS24) & 60.7 & 51.5 & 38.9 & 45.5 & 32.9 & 21.5 & 32.5 & 15.9 & 9.2 & 27.8 & 11.7 & 5.6 \\
 & MGCCFF (AAAI25) & 38.2 & 38.5 & 21.3 & 36.5 & 31.5 & 16.9 & 34.0 & 24.7 & 12.9 & 31.2 & 20.8 & 10.5 \\
 & FreeCSL (CVPR25) & 26.3 & 16.6 & 6.9 & 23.3 & 11.8 & 4.3 & 23.5 & 9.2 & 3.6 & 16.8 & 4.9 & 0.7 \\
 & ROLL (CVPR25) & 75.0 & 72.8 & 59.6 & 52.5 & 49.0 & 37.4 & 41.8 & 24.4 & 15.7 & 35.3 & 17.8 & 10.2 \\
 & PROTOCOL (ICML25) & 55.5 & 59.9 & 44.9 & 54.3 & \underline{60.1} & \underline{44.0} & \underline{59.3} & \textbf{61.3} & \textbf{46.3} & \textbf{55.7} & \textbf{61.7} & \textbf{46.7} \\
\midrule
\multirow{9}{*}{\rotatebox{90}{NUS-WIDE}}
 & OT-CFM & \textbf{19.6$_{\pm0.6}$} & 16.0$_{\pm0.9}$ & 5.5$_{\pm1.2}$ & \textbf{17.8$_{\pm0.3}$} & 15.9$_{\pm2.0}$ & \textbf{5.2$_{\pm0.5}$} & \textbf{15.9$_{\pm0.7}$} & 12.2$_{\pm2.5}$ & \textbf{3.2$_{\pm0.9}$} & \textbf{14.1$_{\pm0.3}$} & 9.5$_{\pm1.9}$ & 1.7$_{\pm0.6}$ \\
 & MFLVC (CVPR22) & 15.6 & \underline{23.1} & 6.2 & 15.1 & \underline{18.6} & 4.4 & 13.0 & 15.3 & \underline{3.2} & 11.2 & 11.7 & 1.7 \\
 & GCFAggMVC (CVPR23) & 17.6 & \textbf{23.2} & \textbf{6.9} & 14.3 & 18.2 & 4.3 & 13.5 & \textbf{15.3} & 3.2 & 11.0 & 11.4 & 1.6 \\
 & MRG-UMC (TNNLS25) & \underline{17.8} & 19.1 & 4.8 & \underline{15.2} & 15.2 & 3.3 & 13.3 & 13.9 & 2.2 & \underline{12.4} & 12.0 & 1.6 \\
 & CANDY (NeurIPS24) & 17.5 & 22.7 & \underline{6.9} & 14.6 & \textbf{18.9} & \underline{4.7} & \underline{13.6} & \underline{15.3} & 3.2 & 11.8 & \underline{12.6} & \underline{1.8} \\
 & MGCCFF (AAAI25) & 13.6 & 7.2 & 0.7 & 12.9 & 6.4 & 0.5 & 12.6 & 5.7 & 0.3 & 12.3 & 5.7 & 0.4 \\
 & FreeCSL (CVPR25) & 10.1 & 10.5 & 1.2 & 9.2 & 10.0 & 0.8 & 9.0 & 9.1 & 0.5 & 8.9 & 8.2 & 0.3 \\
 & ROLL (CVPR25) & 17.2 & 21.3 & 5.7 & 14.3 & 18.2 & 3.9 & 13.2 & 14.6 & 2.9 & 12.2 & \textbf{13.1} & \textbf{1.9} \\
 & PROTOCOL (ICML25) & 15.5 & 17.8 & 3.7 & 12.3 & 13.6 & 2.1 & 11.2 & 10.9 & 1.3 & 10.5 & 8.9 & 0.5 \\
\bottomrule
\end{tabular}
\end{sc}
\end{footnotesize}
\end{center}
\vskip -0.1in
\end{table*}


\textbf{Analysis:} Traditional methods fail catastrophically when alignment is lost. OT-CFM, armed with the Gromov-Wasserstein loss, successfully aligns geometric structures without needing point-wise correspondence, maintaining high accuracy even at high unaligned rates.

% ----------------------------------------------------------------------
\subsection{Ablation Study (RQ4)}
\label{subsec:ablation}

To verify the effectiveness of each module, we conduct ablation studies on the \texttt{Scene-15} dataset. We define the following variants:
\begin{enumerate}
    \item \textbf{w/o GW:} Removing the Gromov-Wasserstein structural alignment loss.
    \item \textbf{w/o Flow:} Replacing the flow matching module with a standard regression loss for imputation.
    \item \textbf{w/o Contrastive:} Removing the contrastive loss (only applicable in aligned settings).
    \item \textbf{w/o Clustering:} Removing the KL-divergence clustering loss (using K-Means on features post-training).
\end{enumerate}

\begin{figure}[ht]
    \centering
    \begin{center}
    \centerline{\includegraphics[width=0.8\columnwidth]{example-image-c}} % Replace with actual ablation_bar.png
    \caption{Ablation study of different components on Scene-15 dataset.}
    \label{fig:ablation}
    \end{center}
\end{figure}

\textbf{Results:} The removal of $\mathcal{L}_{GW}$ leads to a sharp performance drop in unaligned settings, validating its crucial role in structural alignment. Removing the Flow module degrades performance in high-missing-rate scenarios, proving the necessity of generative imputation.

% ----------------------------------------------------------------------
\subsection{Sensitivity and Parameters Analysis}
\label{subsec:sensitivity}

We investigate the sensitivity of OT-CFM to key hyperparameters:
\begin{itemize}
    \item \textbf{Number of ODE Steps ($N$):} We vary $N$ from 1 to 100. Results show that performance saturates around $N=10$, confirming that identifying the optimal transport path allows for few-step generation.
    \item \textbf{Loss Weights ($\lambda_{gw}, \lambda_{c}$):} We analyze the impact of varying the weights for structural alignment and clustering objectives.
\end{itemize}

\begin{figure}[ht]
    \centering
    \begin{center}
    \centerline{\includegraphics[width=0.8\columnwidth]{example-image-a}} % Replace with actual parameter_sensitivity.png
    \caption{Parameter sensitivity analysis for ODE steps and loss weights.}
    \label{fig:sensitivity}
    \end{center}
\end{figure}

% ----------------------------------------------------------------------
\subsection{Visualization and Efficiency (RQ3)}
\label{subsec:vis_efficiency}

\textbf{Latent Space Visualization.} Figure \ref{fig:tsne} visualizes the latent representations using t-SNE throughout the training process. Initially disordered, the specific clusters become compact and well-separated as training progresses, demonstrating the effectiveness of the clustering-guided flow.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.32\columnwidth}
        \includegraphics[width=\linewidth]{example-image-a}
        \caption{Epoch 0}
    \end{subfigure}
    \begin{subfigure}{0.32\columnwidth}
        \includegraphics[width=\linewidth]{example-image-b}
        \caption{Epoch 50}
    \end{subfigure}
    \begin{subfigure}{0.32\columnwidth}
        \includegraphics[width=\linewidth]{example-image-c}
        \caption{Epoch 100}
    \end{subfigure}
    \caption{t-SNE visualization of latent representations during training on NoisyMNIST.}
    \label{fig:tsne}
\end{figure}

\textbf{Inference Speed.} We compare the wall-clock time for sampling/imputation between OT-CFM and the diffusion-based DCG.
% TODO: Insert a small table: Method | Inference Time (s) | Speedup
\textbf{Analysis:} OT-CFM achieves a $10\times$ to $50\times$ speedup over DCG due to the use of straight vector fields and deterministic ODE solvers, making it practical for large-scale applications.


\bibliography{ref}
\bibliographystyle{icml2026}

\end{document}