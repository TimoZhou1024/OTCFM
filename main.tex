\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2026} with \usepackage[nohyperref]{icml2026} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2026}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2026}

\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}

\icmltitlerunning{Optimal Transport Coupled Flow Matching for Alignment-Free and Robust Multi-View Clustering}

\begin{document}

\twocolumn[
  \icmltitle{Optimal Transport Coupled Flow Matching for \\
             Alignment-Free and Robust Multi-View Clustering}

  \icmlsetsymbol{equal}{*}

  \begin{icmlauthorlist}
    \icmlauthor{Anonymous Author}{equal}
  \end{icmlauthorlist}

  \icmlaffiliation{equal}{Anonymous Institution}

  \icmlcorrespondingauthor{Anonymous Author}{anon@example.com}

  \icmlkeywords{Multi-View Clustering, Flow Matching, Optimal Transport, Generative Models}

  \vskip 0.3in
]

\printAffiliationsAndNotice{}

\begin{abstract}
Multi-view clustering (MVC) confronts dual challenges in real-world deployments: data incompleteness (missing views) and structural misalignment (unaligned samples). While Diffusion Models (DMs) have shown promise in generative imputation, their stochastic nature and iterative sampling impose high computational latency, and they inherently lack mechanisms to handle unaligned cross-view structures. We propose \textbf{Optimal Transport Coupled Flow Matching (OT-CFM)}, a unified framework that leverages the deterministic nature of continuous normalizing flows and the geometric properties of Optimal Transport. Unlike traditional methods that require explicit alignment steps or stochastic multistep generation, OT-CFM learns a cross-view flow that optimally transports view-specific latent representations toward a structurally aligned consensus centroid. This process enables deterministic, efficient view completion and alignment-free fusion simultaneously. Specifically, we introduce: (1) a cross-view flow matching objective that learns transformations from each view to the consensus space; (2) a Gromov-Wasserstein structural coupling loss computed on encoded representations that aligns intra-view geometry \textit{without requiring sample correspondences}, making it suitable for unaligned scenarios; (3) a cosine similarity-based soft clustering mechanism; and (4) an optional contrastive regularization for aligned settings where sample correspondences are known. Experiments on benchmark datasets with varying degrees of missingness and misalignment demonstrate that OT-CFM achieves competitive performance with state-of-the-art methods while offering significantly faster inference.
\end{abstract}

\section{Introduction}\label{introduction}

Multi-view clustering (MVC) has attracted significant attention in machine learning and data mining communities due to its ability to leverage complementary information from multiple data sources \cite{yang2022survey,chao2021survey}. By integrating heterogeneous representations such as visual features, textual descriptions, and sensor measurements, MVC methods can achieve superior clustering performance compared to single-view approaches. Traditional MVC methods \cite{kumar2011co,nie2016parameter,zhang2019ae2nets} typically assume that the multi-view data is \textit{ideal}---that is, all views are \textit{complete} (every sample has observations in all views) and \textit{aligned} (samples across different views have known one-to-one correspondences).

However, real-world multi-view data rarely satisfies these ideal assumptions. In practice, we frequently encounter \textit{incomplete} multi-view data where some views are missing for certain samples, and \textit{unaligned} multi-view data where cross-view correspondences are unknown or corrupted. For instance, in medical diagnosis, a patient may have CT scans but lack MRI images due to cost or availability constraints, resulting in incomplete views \cite{lin2022completer}. In cross-lingual document clustering, different language versions of documents may not have explicit correspondence annotations, leading to unaligned views \cite{huang2020partially}. Similarly, in social media analysis, user profiles across different platforms (e.g., Twitter and LinkedIn) often lack explicit linking, creating naturally unaligned multi-view scenarios \cite{gong2019mrgumvc}. How to effectively cluster such non-ideal multi-view data has emerged as a critical research challenge in recent years.

Existing approaches for incomplete and unaligned multi-view clustering can be broadly categorized into three paradigms. \textbf{(1) Imputation-based methods} \cite{lin2022completer,liu2023sure,jin2023dealmvc} first recover missing views through matrix completion or generative models, then apply standard MVC algorithms. For example, COMPLETER \cite{lin2022completer} employs contrastive learning for cross-view prediction, while SURE \cite{liu2023sure} integrates uncertainty estimation into the recovery process. \textbf{(2) Alignment-based methods} \cite{huang2020partially,gong2019mrgumvc,yang2024candy} attempt to infer cross-view correspondences through permutation learning or graph matching. MRG-UMC \cite{gong2019mrgumvc} constructs multi-level reliable guidance for unpaired samples, and CANDY \cite{yang2024candy} addresses dual noisy correspondence via robust contrastive learning. \textbf{(3) Diffusion-based methods} \cite{wang2024dcg} have recently emerged as a powerful paradigm, utilizing conditional diffusion models to recover missing views. DCG \cite{wang2024dcg} employs diffusion steps to enhance clustering compactness through iterative denoising.

Despite considerable progress, existing methods suffer from several critical limitations. \textbf{First}, imputation-based and diffusion-based methods rely on stochastic differential equations (SDEs) that necessitate hundreds of sampling steps \cite{ho2020ddpm,song2021scorebased}, resulting in prohibitive computational latency for real-time applications. \textbf{Second}, most methods treat incomplete and unaligned scenarios separately, employing distinct pipelines for imputation and alignment, which leads to error propagation and suboptimal multi-view fusion. \textbf{Third}, existing alignment methods often require explicit correspondence supervision or expensive combinatorial optimization (e.g., Hungarian algorithm with $O(N^3)$ complexity), limiting their scalability to large-scale datasets.

To address these limitations, we propose \textbf{Optimal Transport Coupled Flow Matching (OT-CFM)}, a unified framework that simultaneously handles incomplete and unaligned multi-view clustering in a principled manner. Our key insight is that Flow Matching (FM) \cite{lipman2023flowmatching,liu2023rectifiedflow} provides a simulation-free approach to training Continuous Normalizing Flows (CNFs), enabling deterministic and efficient probability path construction. By regressing a target vector field rather than iteratively denoising, FM achieves comparable generation quality with orders of magnitude fewer function evaluations \cite{tong2024otcfm}. Furthermore, the theoretical connection between FM and Optimal Transport (OT) suggests a principled way to learn geometrically optimal trajectories between view-specific distributions.

Specifically, OT-CFM reformulates multi-view clustering as learning a flow that transports view-specific latent representations to a unified consensus space. Our framework introduces: \textbf{(1)} A \textit{Cross-View Flow Matching} mechanism that learns transformations from each view's latent space toward a shared consensus, enabling efficient missing view imputation through deterministic ODE solving with only 10 function evaluations. \textbf{(2)} A \textit{Gromov-Wasserstein Structural Regularization} computed on encoded representations that aligns intra-view geometric structures \textit{without requiring sample correspondences}, making it naturally suitable for unaligned scenarios. \textbf{(3)} A modular loss design where \textit{Contrastive Regularization} is applied only when correspondences are known (aligned setting), while GW-based alignment operates in all scenarios. \textbf{(4)} A \textit{Cosine Similarity-based Clustering} mechanism with temperature-scaled softmax assignments for improved clustering performance.

This paper makes the following contributions:
\begin{itemize}
    \item We propose OT-CFM, the first unified framework that addresses both incomplete and unaligned multi-view clustering through flow matching, achieving deterministic inference with significantly lower latency than diffusion-based methods.
    \item We develop a Gromov-Wasserstein structural coupling loss that enforces cross-view geometric consistency \textit{without requiring sample correspondences}, enabling true alignment-free multi-view learning.
    \item We introduce a modular architecture that adaptively activates contrastive learning for aligned data while relying on GW-based structural alignment for unaligned scenarios.
    \item Extensive experiments on benchmark datasets demonstrate that OT-CFM achieves competitive or superior performance compared to state-of-the-art methods while offering 10-100$\times$ faster inference.
\end{itemize}

\section{Related Work}\label{related-work}

\textbf{Generative Models in MVC.} Deep generative models have evolved from Variational Autoencoders (VAEs) to Generative Adversarial Networks (GANs). Recently, Diffusion Models have dominated IMVC. Methods like IMVCDC utilize latent diffusion for missing view imputation, while DCG (Diffusion Contrastive Generation) employs diffusion steps to enhance clustering compactness. However, these methods are fundamentally limited by the computational cost of iterative denoising and the requirement for paired training data.

\textbf{Flow Matching and Optimal Transport.} Flow Matching simplifies the training of CNFs by directly regressing vector fields. Rectified Flow and Conditional Flow Matching (CFM) further optimize transport paths to be nearly straight, facilitating fast ODE solving. Concurrently, Optimal Transport (OT) has been applied to domain adaptation and alignment. Our work bridges these fields, utilizing OT to guide the flow matching process for multi-view structural alignment.

\textbf{Unaligned Multi-View Learning.} Traditional UMVC relies on combinatorial optimization to find permutation matrices or constructing large-scale similarity graphs, scaling poorly with dataset size ($O(N^2)$ or $O(N^3)$). Our method avoids explicit permutation solving by learning continuous transport maps, reducing complexity while handling misalignment.

\section{Preliminaries on Flow Matching for Multi-View Clustering}\label{preliminaries}

\subsection{Problem Formulation}\label{problem-formulation}

Consider a dataset with $V$ views $\mathcal{X} = \{ \mathbf{X}^{(v)} \}_{v=1}^V$, where $\mathbf{X}^{(v)} \in \mathbb{R}^{N \times d_v}$. In the general setting, both missing instances (IMVC) and unknown correspondences (UMVC) may exist. The goal is to learn a partition $\mathcal{C}$ of $K$ clusters.

\subsection{Flow Matching Basics}\label{flow-matching-basics}

Flow Matching aims to learn a time-dependent vector field $u_t: \mathbb{R}^d \to \mathbb{R}^d$ that generates a probability path $p_t$ transforming a source distribution $p_0$ (noise) to a target distribution $p_1$ (data). The flow is defined by the ODE:
\[
\frac{d\mathbf{z}_t}{dt} = u_t(\mathbf{z}_t), \quad \mathbf{z}_0 \sim p_0
\]
The Conditional Flow Matching (CFM) objective allows training without explicit access to $p_t$ and $u_t$ by conditioning on data samples $\mathbf{x}_1 \sim p_1$:
\[
\mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t, q(\mathbf{z}_1), p_t(\mathbf{z}|\mathbf{z}_1)} \| v_\theta(\mathbf{z}, t) - u_t(\mathbf{z}|\mathbf{z}_1) \|^2
\]
where $u_t(\mathbf{z}|\mathbf{z}_1)$ is the conditional vector field, typically chosen to induce a straight path $\mathbf{z}_t = t\mathbf{x}_1 + (1-t)\mathbf{x}_0$.

\section{Optimal Transport Coupled Flow Matching (OT-CFM)}\label{method}

We propose OT-CFM to address the structural misalignment and computational inefficiency of current methods. The framework consists of latent embedding, OT-guided vector field learning, and deterministic ODE fusion.

\subsection{Latent Space Construction}\label{latent-space}

We address the challenge of high-dimensional and heterogeneous multi-view data by projecting raw features into a unified low-dimensional latent space. Let $\mathcal{X} = \{ \mathbf{X}^{(v)} \in \mathbb{R}^{N \times d_v} \}_{v=1}^V$ denote the multi-view dataset with $N$ samples and $V$ views. For each view $v$, we employ a specific neural encoder $f_{\phi_v}: \mathbb{R}^{d_v} \to \mathbb{R}^{d_z}$ parameterized by $\phi_v$ to map the observation $\mathbf{x}_i^{(v)}$ to a latent representation $\mathbf{z}_i^{(v)} = f_{\phi_v}(\mathbf{x}_i^{(v)})$. 

\textbf{Encoder Architecture.} Each view-specific encoder is implemented as a multi-layer perceptron (MLP) with batch normalization, ReLU activation, and dropout regularization. To facilitate gradient flow and preserve low-level features, we incorporate a scaled skip connection from input to output:
\[
\mathbf{z}^{(v)} = \text{MLP}_{\phi_v}(\mathbf{x}^{(v)}) + \alpha \cdot W_{skip} \mathbf{x}^{(v)}
\]
where $\alpha = 0.1$ is a scaling factor and $W_{skip}$ is a linear projection when $d_v \neq d_z$.

\textbf{Decoder Architecture.} Symmetric to the encoders, we employ view-specific decoders $g_{\psi_v}: \mathbb{R}^{d_z} \to \mathbb{R}^{d_v}$ that reconstruct the original views from latent representations. This autoencoder structure provides a reconstruction objective that regularizes the latent space.

\textbf{Consensus Fusion (Aligned Setting).} For aligned multi-view data where sample correspondences are known, the multi-view consensus representation is obtained by averaging the view-specific latents:
\[
\mathbf{z}^{(c)} = \frac{1}{|\mathcal{V}_{avail}|} \sum_{v \in \mathcal{V}_{avail}} \mathbf{z}^{(v)}
\]
where $\mathcal{V}_{avail}$ denotes the set of available views. This averaging is semantically meaningful because $\mathbf{z}_i^{(v)}$ and $\mathbf{z}_i^{(u)}$ correspond to the same underlying sample $i$.

\textbf{Centroid-based Conditioning (Unaligned Setting).} For unaligned multi-view data (UMVC), the $i$-th sample in view $v$ does \textit{not} correspond to the $i$-th sample in view $u$. Therefore, \textbf{any cross-view operation based on sample index $i$ is mathematically invalid}---this includes not only feature averaging but also soft-voting of cluster assignments. Instead, each view must independently determine its own conditioning:
\begin{enumerate}
    \item For view $v$, compute soft cluster assignments $q_{ik}^{(v)}$ based solely on $\mathbf{z}_i^{(v)}$ and the shared centroids $\{\boldsymbol{\mu}_k\}_{k=1}^K$.
    \item Determine the view-specific cluster: $k^{*(v)} = \argmax_k q_{ik}^{(v)}$.
    \item Use $\boldsymbol{\mu}_{k^{*(v)}}$ as the conditioning for view $v$'s sample $i$.
\end{enumerate}
Critically, \textbf{each view operates entirely independently}. View $A$'s sample flows toward the centroid that View $A$ assigns it to; View $B$'s sample flows toward View $B$'s assigned centroid. Cross-view alignment is achieved \textit{solely} through the GW loss, which aligns the geometric structure of the latent distributions without requiring any sample-level correspondence.

This encoding process serves two primary purposes: it reduces the computational complexity of the subsequent flow matching operations by operating in a lower-dimensional manifold $d_z \ll d_v$, and it filters out modality-specific noise while preserving the intrinsic semantic structure. The resulting latent representations $\mathcal{Z} = \{ \mathbf{Z}^{(v)} \in \mathbb{R}^{N \times d_z} \}_{v=1}^V$ form the basis for our flow-based alignment and generation mechanism.

\subsection{Gromov-Wasserstein Guided Vector Field}\label{gw-vector-field}

In the context of Unaligned Multi-View Clustering (UMVC), the correspondence between samples across different views is unknown, rendering standard point-wise distance minimization invalid. To overcome this, we leverage the Gromov-Wasserstein (GW) distance to align the geometric structures of the view-specific distributions. We define the intra-view relational geometry using kernel matrices computed on the encoded latent representations.

\textbf{Kernel Matrix Construction.} Let $\mathbf{K}^{(v)} \in \mathbb{R}^{B \times B}$ represent the pairwise similarity matrix for view $v$ within a mini-batch of size $B$. We employ the RBF (Radial Basis Function) kernel:
\[
K_{ij}^{(v)} = \exp\left(-\gamma \| \mathbf{z}_i^{(v)} - \mathbf{z}_j^{(v)} \|^2\right)
\]
where $\gamma$ is the kernel bandwidth parameter. To ensure numerical stability, we normalize the kernel matrix to the range $[0, 1]$.

\textbf{Structural Alignment Loss.} The GW loss measures the Frobenius norm of the difference between kernel matrices across view pairs:
\[
\mathcal{L}_{GW} = \frac{2}{V(V-1)} \sum_{v < u} \| \mathbf{K}^{(v)} - \mathbf{K}^{(u)} \|_F^2
\]
This formulation encourages the pairwise geometric relationships to be consistent across views without requiring explicit sample correspondences. By minimizing this loss, samples with similar topological roles in their respective views are encouraged to have similar relative positions in the latent space.

Note that in our implementation, the GW loss is computed on the encoded latent representations $\mathbf{z}^{(v)}$ directly, rather than on the intermediate states $\mathbf{z}_t$ during the flow process. This design choice simplifies the computation while still providing effective structural alignment through the gradient signal that propagates back to the encoder parameters.

\textbf{Computational Complexity.} While GW distance computation scales quadratically with sample size, we compute it within mini-batches of size $B$, yielding $O(B^2)$ per batch. Since our goal is to align the \textit{manifold geometry} rather than global point-wise matching, batch-wise structural alignment provides a sufficient gradient signal for the encoders while maintaining linear complexity $O(N)$ with respect to the total dataset size.

\textbf{Batch Size Considerations.} The effectiveness of batch-wise GW alignment depends on having sufficiently diverse samples within each batch to capture meaningful geometric structure. We recommend $B \geq 128$ for stable training. In our experiments, we use $B = 256$ by default. For datasets with many fine-grained clusters, larger batch sizes or stratified sampling may be beneficial to ensure adequate cluster representation within each batch.

\subsection{Conditional Straight-Flow for Imputation}\label{conditional-flow}

To address the Incomplete Multi-View Clustering (IMVC) problem, we formulate the missing view imputation as a conditional generation task within the flow matching framework. Let $\mathcal{V}_{avail}$ denote the set of indices for observed views and $\mathcal{V}_{miss}$ for missing views. We aim to learn a time-dependent vector field $v_\theta(\mathbf{z}_t, t, \mathbf{c})$ that generates the missing latent representations conditioned on a conditioning vector $\mathbf{c}$.

\textbf{Conditioning Strategy.} The choice of conditioning $\mathbf{c}$ depends on the data alignment:
\begin{itemize}
    \item \textbf{Aligned (IMVC):} $\mathbf{c} = \mathbf{z}^{(c)}$, the consensus computed from available views.
    \item \textbf{Unaligned (UMVC):} $\mathbf{c} = \boldsymbol{\mu}_{k^*}$, the nearest cluster centroid based on available view latents.
\end{itemize}

\textbf{Remark on Instance Specificity.} In the unaligned setting, conditioning on cluster centroids $\boldsymbol{\mu}_{k^*}$ rather than instance-specific features means that imputed views represent \textit{prototypical} samples of the assigned cluster, not pixel-accurate reconstructions of the original instance. This is an inherent property of unaligned imputation: without cross-view correspondence, instance-level recovery is fundamentally impossible. However, for the downstream \textit{clustering} task, semantic correctness (i.e., assigning samples to the correct cluster) matters more than visual fidelity. Our framework prioritizes clustering accuracy over reconstruction quality, which is the appropriate objective for UMVC.

\textbf{Imputation Procedure.} During inference, for samples with missing views, we:
\begin{enumerate}
    \item Encode all available views to obtain $\{\mathbf{z}^{(v)}\}_{v \in \mathcal{V}_{avail}}$.
    \item Compute the conditioning vector $\mathbf{c}$ (consensus or cluster centroid).
    \item Sample initial noise $\mathbf{z}_0 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ for each missing view.
    \item Solve the ODE $\frac{d\mathbf{z}_t}{dt} = v_\theta(\mathbf{z}_t, t, \mathbf{c})$ using the Euler method with $N_{steps} = 10$ integration steps.
    \item Decode the generated latent to obtain the imputed view.
\end{enumerate}

We adopt the Optimal Transport Conditional Flow Matching (OT-CFM) formulation, which constructs a probability path that optimally transports a standard Gaussian noise distribution $p_0(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I})$ to the data distribution $p_1(\mathbf{z})$. The target conditional vector field $u_t(\mathbf{z} | \mathbf{z}_0, \mathbf{z}_1)$ is defined to generate straight trajectories:
\[
u_t(\mathbf{z} | \mathbf{z}_0, \mathbf{z}_1) = \mathbf{z}_1 - (1 - \sigma_{min})\mathbf{z}_0
\]
corresponding to the interpolation path $\mathbf{z}_t = (1 - (1 - \sigma_{min})t)\mathbf{z}_0 + t\mathbf{z}_1$, where $\sigma_{min} = 10^{-4}$ is a small constant for numerical stability.

\textbf{Vector Field Architecture.} The neural vector field $v_\theta$ employs a residual architecture with time conditioning. Time is embedded using sinusoidal positional encoding followed by an MLP, similar to diffusion models. The network consists of residual blocks where each block incorporates the time embedding through an additive modulation:
\[
\mathbf{h}_{l+1} = \mathbf{h}_l + \text{MLP}(\text{LayerNorm}(\mathbf{h}_l) + \text{TimeEmbed}(t))
\]

The linearity of the OT-CFM path allows us to employ fixed-step ODE solvers with a very small number of function evaluations (NFE $\leq 10$), resulting in a deterministic and computationally efficient imputation process.

\subsection{Overall Objective Function}\label{overall-objective}

The training of the OT-CFM framework is governed by a unified objective function that integrates flow matching accuracy, structural alignment, clustering compactness, reconstruction fidelity, and cross-view consistency. 

\textbf{Generative Flow Matching Loss.} We adopt the standard Conditional Flow Matching (CFM) objective that learns to transport noise to data, conditioned on a semantic anchor. Let $\mathbf{z}_0 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ be the noise sample, $\mathbf{z}_1$ be the target latent (data), and $\mathbf{c}$ be the conditioning vector (consensus for aligned, cluster centroid for unaligned). The CFM loss is:
\[
\mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t \sim [0,1], \mathbf{z}_0, \mathbf{z}_1} \left[ \| v_\theta(\mathbf{z}_t, t, \mathbf{c}) - (\mathbf{z}_1 - (1-\sigma_{min})\mathbf{z}_0) \|^2 \right]
\]
where $\mathbf{z}_t = (1 - (1 - \sigma_{min})t)\mathbf{z}_0 + t\mathbf{z}_1$ is the interpolation path. This formulation trains a \textit{generative} flow (Noise $\to$ Data) that can synthesize missing view latents at inference time.

\textbf{Remark.} An alternative \textit{cross-view} formulation learns to flow from view latents to consensus: $\psi_t(\mathbf{z}^{(v)}, \mathbf{z}^{(c)})$. While this provides an auxiliary training signal for representation learning, the \textit{generative} formulation above is essential for imputation, as it enables sampling from noise.

\textbf{Gromov-Wasserstein Structural Alignment.} To enforce geometric consistency across unaligned views, we incorporate the Gromov-Wasserstein regularization $\mathcal{L}_{GW}$ computed on the encoded latent representations using RBF kernel matrices.

\textbf{Clustering Loss.} We employ a cosine similarity-based soft assignment mechanism. Let $\tilde{\mathbf{z}}_i = \mathbf{z}_i / \|\mathbf{z}_i\|$ and $\tilde{\boldsymbol{\mu}}_k = \boldsymbol{\mu}_k / \|\boldsymbol{\mu}_k\|$ denote the normalized embeddings and centroids. The soft assignment probability is computed via temperature-scaled softmax:
\[
q_{ik} = \frac{\exp(\tilde{\mathbf{z}}_i^\top \tilde{\boldsymbol{\mu}}_k / \tau)}{\sum_{j=1}^{K} \exp(\tilde{\mathbf{z}}_i^\top \tilde{\boldsymbol{\mu}}_j / \tau)}
\]
where $\tau$ is the temperature parameter. The auxiliary target distribution $P$ sharpens high-confidence assignments: $p_{ik} \propto q_{ik}^2 / \sum_i q_{ik}$. The clustering loss is the KL divergence:
\[
\mathcal{L}_{Cluster} = KL(P \| Q) = \sum_{i} \sum_{k} p_{ik} \log \frac{p_{ik}}{q_{ik}}
\]

\textbf{Reconstruction Loss.} To preserve view-specific information and regularize the latent space, we include a reconstruction loss through view-specific decoders:
\[
\mathcal{L}_{Recon} = \frac{1}{V} \sum_{v=1}^{V} \| \mathbf{X}^{(v)} - g_{\psi_v}(\mathbf{z}^{(v)}) \|_F^2
\]
where $g_{\psi_v}$ is the decoder for view $v$.

\textbf{Contrastive Loss (Aligned Setting Only).} For scenarios where sample correspondences are known (standard IMVC), we can additionally employ an InfoNCE-based contrastive loss to enhance cross-view consistency:
\[
\mathcal{L}_{Contrastive} = -\frac{1}{V(V-1)} \sum_{v \neq u} \sum_{i} \log \frac{\exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\mathbf{z}}_i^{(u)} / \tau_c)}{\sum_{j} \exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\mathbf{z}}_j^{(u)} / \tau_c)}
\]
where $\tau_c$ is the contrastive temperature. \textbf{Importantly, this loss is only applicable when sample correspondences across views are available.} In the unaligned setting (UMVC), where the $i$-th sample in view $v$ does not correspond to the $i$-th sample in view $u$, this loss must be disabled ($\lambda_{con} = 0$). The GW loss $\mathcal{L}_{GW}$ serves as the sole mechanism for cross-view structural alignment in UMVC, as it operates on pairwise geometric relationships rather than point-wise correspondences.

\textbf{Total Objective.} The complete objective is a weighted combination:
\[
\mathcal{L}_{Total} = \mathcal{L}_{CFM} + \lambda_{gw} \mathcal{L}_{GW} + \lambda_{c} \mathcal{L}_{Cluster} + \lambda_{r} \mathcal{L}_{Recon} + \lambda_{con} \mathcal{L}_{Contrastive}
\]
where we set $\lambda_{gw} = 0.2$, $\lambda_{c} = 1.0$, $\lambda_{r} = 0.5$ as default hyperparameters. The contrastive weight $\lambda_{con}$ is set to $0.3$ for aligned data and $0$ for unaligned data. Table~\ref{tab:loss_config} summarizes the loss configurations for different scenarios.

\begin{table}[h]
\centering
\caption{Loss function configuration for different MVC scenarios.}
\label{tab:loss_config}
\begin{tabular}{lcc}
\toprule
\textbf{Component} & \textbf{Aligned (IMVC)} & \textbf{Unaligned (UMVC)} \\
\midrule
\textbf{Flow Conditioning} & Consensus $\mathbf{z}^{(c)}$ & Centroid $\boldsymbol{\mu}_{k^*}$ \\
$\mathcal{L}_{CFM}$ (Generative) & \checkmark & \checkmark \\
$\mathcal{L}_{GW}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Cluster}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Recon}$ & \checkmark & \checkmark \\
$\mathcal{L}_{Contrastive}$ & \checkmark & $\times$ \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\footnotesize{The generative CFM loss is always active; only the conditioning source differs.}
\end{table}

\subsection{Optimization Procedure}\label{optimization}

Directly optimizing the joint objective $\mathcal{L}_{Total}$ is challenging due to the coupling between the flow matching dynamics, the structural alignment, and the discrete nature of clustering assignments. We adopt an end-to-end training approach with periodic clustering refinement, which offers better gradient flow while maintaining clustering quality.

\textbf{Network Architecture.} Our encoder-decoder architecture employs view-specific MLP encoders with skip connections to map high-dimensional inputs to a shared latent space. Each encoder consists of fully-connected layers with batch normalization, ReLU activation, and dropout regularization. A scaled skip connection ($0.1\times$) from input to output helps preserve low-level features. The vector field network uses residual blocks with time conditioning via sinusoidal embeddings, following the design principles of diffusion models.

\textbf{Training Procedure.} The optimization follows a three-phase approach to address the cold-start problem, where good centroids require a stable latent space with clear cluster structure:
\begin{enumerate}
    \item \textbf{Warm-up Phase I (Representation Learning):} We first train the encoder-decoder using $\mathcal{L}_{Recon}$ for a few epochs to establish a stable latent manifold.
    \item \textbf{Warm-up Phase II (Single-View DEC):} After initial reconstruction training, we initialize cluster centroids via K-Means and apply \textit{single-view DEC clustering loss} within each view independently:
    \[
    \mathcal{L}_{SV\text{-}DEC} = \frac{1}{V} \sum_{v=1}^{V} KL(P^{(v)} \| Q^{(v)})
    \]
    where $Q^{(v)}$ and $P^{(v)}$ are the soft assignments and target distributions computed on view $v$'s latent space. This ensures that \textbf{each view develops cluster-separable representations before cross-view alignment}, providing semantically meaningful initial centroids for the joint training phase.
    \item \textbf{Joint Training Phase:} We perform end-to-end optimization of all network parameters using the combined loss $\mathcal{L}_{Total}$. The cluster centroids are treated as learnable parameters updated via gradient descent. Periodically (every few epochs), we refine the centroids using K-Means on the current embeddings to prevent degenerate solutions.
\end{enumerate}

\textbf{Mitigating Mode Collapse.} The cold-start problem poses a risk of mode collapse in unaligned settings: poor initial centroids lead to poor conditioning, which in turn degrades latent representations. We address this through: (1) the two-phase warm-up that first establishes a stable latent manifold via reconstruction, then develops cluster-separable representations via single-view DEC before introducing cross-view alignment; (2) periodic K-Means refinement that corrects drifting centroids; and (3) the GW loss that provides centroid-independent structural guidance. The single-view DEC phase is particularly crucial: it ensures that even before any cross-view information is used, each view's latent space already exhibits meaningful cluster structure, providing high-quality initial centroids that significantly improve the subsequent joint optimization. We empirically validate these design choices in our ablation studies.

\textbf{Implementation Details.} We use the Adam optimizer with learning rate $10^{-3}$ and apply gradient clipping with max norm 1.0 to stabilize training. The ODE solver employs the Euler method with 10 integration steps for efficiency. During inference, cluster assignments are obtained by taking the argmax of the soft assignment probabilities.

The complete training process is summarized in Algorithm \ref{alg:ot_cfm}.

\begin{algorithm}[tb]
  \caption{End-to-End Training for OT-CFM}
  \label{alg:ot_cfm}
  \begin{algorithmic}
    \STATE {\bfseries Input:} Multi-view data $\mathcal{X}$, Number of clusters $K$, Hyperparameters $\lambda_{gw}, \lambda_{c}, \lambda_{r}, \lambda_{con}$, Alignment flag \texttt{is\_aligned}.
    \STATE {\bfseries Initialize:} Encoder-decoder parameters $\phi$, Vector field parameters $\theta$, Cluster centroids $\mathbf{M}$ via K-Means on initial embeddings.
    \FOR{epoch $= 1$ to $E$}
    \FOR{each mini-batch $\mathcal{B} \subset \mathcal{X}$}
        \STATE Encode views: $\mathbf{z}^{(v)} = f_{\phi_v}(\mathbf{x}^{(v)})$ for all views.
        \IF{\texttt{is\_aligned}}
            \STATE Compute consensus: $\mathbf{z}^{(c)} = \frac{1}{V}\sum_v \mathbf{z}^{(v)}$.
            \STATE Condition $\mathbf{c} \gets \mathbf{z}^{(c)}$.
        \ELSE
            \STATE \textit{// Unaligned: each view operates independently.}
            \STATE For each view $v$ and sample $i$:
            \STATE \quad $q_{ik}^{(v)} = \frac{\exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\boldsymbol{\mu}}_k / \tau)}{\sum_j \exp(\tilde{\mathbf{z}}_i^{(v)\top} \tilde{\boldsymbol{\mu}}_j / \tau)}$
            \STATE \quad $k^{*(v)}_i = \argmax_k q_{ik}^{(v)}$
            \STATE \quad Condition $\mathbf{c}_i^{(v)} \gets \boldsymbol{\mu}_{k^{*(v)}_i}$
            \STATE \textit{// No cross-view voting: index $i$ has no correspondence.}
        \ENDIF
        \STATE Sample noise $\mathbf{z}_0 \sim \mathcal{N}(0, I)$ and time $t \sim \mathcal{U}[0,1]$.
        \STATE Compute CFM Loss: $\mathcal{L}_{CFM} = \| v_\theta(\mathbf{z}_t, t, \mathbf{c}) - (\mathbf{z}_1 - (1-\sigma_{min})\mathbf{z}_0) \|^2$.
        \STATE Compute GW Alignment Loss $\mathcal{L}_{GW}$ on encoded latents.
        \STATE Compute Clustering Loss $\mathcal{L}_{Cluster} = KL(P_{\mathcal{B}} \| Q_{\mathcal{B}})$.
        \STATE Compute $\mathcal{L}_{Recon}$; compute $\mathcal{L}_{Contrastive}$ only if \texttt{is\_aligned}.
        \STATE Update all parameters via Adam with gradient clipping.
    \ENDFOR
    \IF{epoch mod $T_{update} = 0$}
        \STATE Refine centroids $\mathbf{M}$ via K-Means on current embeddings.
    \ENDIF
    \ENDFOR
    \STATE {\bfseries Output:} Trained model, Cluster assignments $\argmax_k q_{ik}$.
  \end{algorithmic}
\end{algorithm}


\bibliography{ref}
\bibliographystyle{icml2026}

\end{document}